{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e7f32e",
   "metadata": {},
   "source": [
    "# Fourier Feature INR (Implicit Neural Representation) for BraTS 2023 Tumour Segmentation (JAX)\n",
    "\n",
    "This notebook implements a coordinate-based MLP (implicit neural representation) with Fourier feature embeddings trained to predict voxel-wise tumour labels for BraTS 2023 volumes.\n",
    "\n",
    "Instead of a 3D CNN (e.g. nnU-Net), we treat segmentation as learning a function: \n",
    "$(f: (x,y,z, m_{t_{1n}}, m_{t_{1c}}, m_{t_{2w}}, m_{t_{2f}}) \\rightarrow \\texttt{class logits})$.\n",
    "\n",
    "We sample coordinates and associated multi-modal intensities to train an MLP with Fourier features for higher frequency representation capacity.\n",
    "\n",
    "Notes: \n",
    "- This is a proof-of-concept; full convergence requires many iterations.\n",
    "- Memory/time constraints mean we sample sparse coordinates per step.\n",
    "- BraTS labels: 0=background, 1=NCR/NET, 2=ED, 3=ET.\n",
    "- Dice scores are computed per class on a validation case.\n",
    "- Compare conceptually to nnU-Net (dense 3D convolutions + data augmentation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, math, json, time, pathlib, functools\n",
    "from typing import Tuple, Dict, Any\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import nibabel as nib\n",
    "import wandb\n",
    "from dataclasses import dataclass\n",
    "\n",
    "print('JAX devices:', jax.devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8291567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration (Enhanced + Cross-Validation + W&B)\n",
    "DATA_ROOT = pathlib.Path('../data/BraTS-2023')  # dataset root\n",
    "SAVE_PATH = pathlib.Path('../artifacts/inr_brats23.npz')\n",
    "CASE_LIMIT = 256                  # Max cases to use (subset of full set)\n",
    "NUM_FOLDS = 5                     # K for K-fold cross-validation\n",
    "FOLD_INDEX = 0                    # Which fold acts as validation/test (0-based)\n",
    "GLOBAL_BATCH_SIZE = 32768\n",
    "MICRO_BATCH_SIZE = 2048\n",
    "FOURIER_FREQS = 4\n",
    "HIDDEN_DIMS = [128, 256, 256, 4]\n",
    "LR = 1e-3\n",
    "MIN_LR = 5e-5\n",
    "WARMUP_STEPS = 50\n",
    "TRAIN_STEPS = 500\n",
    "VAL_CASE_INDEX = 0\n",
    "RNG_SEED = 72\n",
    "NUM_CLASSES = 4\n",
    "DICE_WEIGHT = 0.2\n",
    "CLASS_WEIGHTS = [1.0,1.0,1.0,1.0]\n",
    "CLIP_NORM = 1.0\n",
    "\n",
    "# W&B Configuration\n",
    "WANDB_PROJECT = \"brats-inr-segmentation\"\n",
    "WANDB_ENTITY = None  # Set to your wandb username/team, or leave None for default\n",
    "WANDB_RUN_NAME = None  # Auto-generated if None\n",
    "WANDB_TAGS = [\"fourier-features\", \"INR\", \"medical-imaging\", \"segmentation\"]\n",
    "WANDB_NOTES = \"Fourier Feature INR for BraTS 2023 with cross-validation\"\n",
    "\n",
    "# ACCUM steps derived from global vs micro batch\n",
    "ACCUM_STEPS = (GLOBAL_BATCH_SIZE + MICRO_BATCH_SIZE - 1)//MICRO_BATCH_SIZE\n",
    "print(f'Using CASE_LIMIT={CASE_LIMIT} NUM_FOLDS={NUM_FOLDS} FOLD_INDEX={FOLD_INDEX}')\n",
    "jax_key = jax.random.PRNGKey(RNG_SEED)\n",
    "\n",
    "# Initialize W&B\n",
    "config = {\n",
    "    \"case_limit\": CASE_LIMIT,\n",
    "    \"num_folds\": NUM_FOLDS,\n",
    "    \"fold_index\": FOLD_INDEX,\n",
    "    \"global_batch_size\": GLOBAL_BATCH_SIZE,\n",
    "    \"micro_batch_size\": MICRO_BATCH_SIZE,\n",
    "    \"accum_steps\": ACCUM_STEPS,\n",
    "    \"fourier_freqs\": FOURIER_FREQS,\n",
    "    \"hidden_dims\": HIDDEN_DIMS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"min_lr\": MIN_LR,\n",
    "    \"warmup_steps\": WARMUP_STEPS,\n",
    "    \"train_steps\": TRAIN_STEPS,\n",
    "    \"num_classes\": NUM_CLASSES,\n",
    "    \"dice_weight\": DICE_WEIGHT,\n",
    "    \"class_weights\": CLASS_WEIGHTS,\n",
    "    \"clip_norm\": CLIP_NORM,\n",
    "    \"rng_seed\": RNG_SEED,\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project=WANDB_PROJECT,\n",
    "    entity=WANDB_ENTITY,\n",
    "    name=WANDB_RUN_NAME,\n",
    "    config=config,\n",
    "    tags=WANDB_TAGS,\n",
    "    notes=WANDB_NOTES,\n",
    ")\n",
    "\n",
    "print(f\"W&B Run: {wandb.run.name}\")\n",
    "print(f\"W&B URL: {wandb.run.url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baac498",
   "metadata": {},
   "source": [
    "## Data Loading Utilities\n",
    "We load each BraTS case's modalities and segmentation. Modalities are z-score normalized per volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59360bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODALITY_SUFFIXES = ['t1n', 't1c', 't2w', 't2f']\n",
    "SEG_SUFFIX = 'seg'\n",
    "\n",
    "def find_cases(root: pathlib.Path):\n",
    "    cases = []\n",
    "    for p in sorted(root.iterdir()):\n",
    "        if p.is_dir():\n",
    "            if any((p / f'{p.name}-{m}.nii.gz').exists() for m in MODALITY_SUFFIXES):\n",
    "                cases.append(p)\n",
    "    return cases\n",
    "\n",
    "def load_case(case_dir: pathlib.Path):\n",
    "    base = case_dir.name\n",
    "    mods = []\n",
    "    for suf in MODALITY_SUFFIXES:\n",
    "        fp = case_dir / f'{base}-{suf}.nii.gz'\n",
    "        img = nib.load(str(fp))\n",
    "        arr = img.get_fdata().astype(np.float32)\n",
    "        mask = arr != 0\n",
    "        if mask.any():\n",
    "            mu = arr[mask].mean(); sigma = arr[mask].std() + 1e-6\n",
    "            arr = (arr - mu) / sigma\n",
    "        mods.append(arr)\n",
    "    seg_fp = case_dir / f'{base}-{SEG_SUFFIX}.nii.gz'\n",
    "    seg = nib.load(str(seg_fp)).get_fdata().astype(np.int16)\n",
    "    mods_arr = np.stack(mods, axis=0)  # (M,H,W,D)\n",
    "    return mods_arr, seg\n",
    "\n",
    "# Discover and subset cases\n",
    "all_cases_full = find_cases(DATA_ROOT)\n",
    "subset_cases = all_cases_full[:CASE_LIMIT]\n",
    "print('Total discovered:', len(all_cases_full), 'Subset used:', len(subset_cases))\n",
    "\n",
    "# Shuffle cases deterministically and create folds\n",
    "rng = np.random.default_rng(RNG_SEED)\n",
    "shuffled = list(subset_cases)\n",
    "rng.shuffle(shuffled)\n",
    "# Split into NUM_FOLDS (last folds may differ by 1 if not divisible)\n",
    "folds = np.array_split(shuffled, NUM_FOLDS)\n",
    "assert 0 <= FOLD_INDEX < len(folds), 'FOLD_INDEX out of range'\n",
    "val_cases = list(folds[FOLD_INDEX])\n",
    "train_cases = [c for i,f in enumerate(folds) if i!=FOLD_INDEX for c in f]\n",
    "print(f'Fold sizes: {[len(f) for f in folds]} | Train={len(train_cases)} Val={len(val_cases)}')\n",
    "\n",
    "# Log dataset info to W&B\n",
    "wandb.config.update({\n",
    "    \"total_cases\": len(all_cases_full),\n",
    "    \"train_cases\": len(train_cases),\n",
    "    \"val_cases\": len(val_cases),\n",
    "    \"fold_sizes\": [len(f) for f in folds],\n",
    "})\n",
    "\n",
    "# Aliases for supervised notation\n",
    "X_train_cases = train_cases\n",
    "Y_train_cases = train_cases  # segmentation labels paired implicitly\n",
    "X_val_cases = val_cases\n",
    "Y_val_cases = val_cases\n",
    "\n",
    "# Quick peek\n",
    "if len(val_cases):\n",
    "    sm_mods, sm_seg = load_case(val_cases[0])\n",
    "    print('Example val case modalities shape', sm_mods.shape, 'seg shape', sm_seg.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e574e5",
   "metadata": {},
   "source": [
    "## Coordinate + Feature Sampling\n",
    "We sample random voxel coordinates and gather their modality intensities and labels for stochastic training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e151400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Streaming Data Loader - Memory Efficient Version\n",
    "# ============================================================================\n",
    "\n",
    "class StreamingBraTSCache:\n",
    "    \"\"\"Lightweight cache that keeps NumPy arrays and samples on-demand\"\"\"\n",
    "    def __init__(self, case_paths, name=\"cache\"):\n",
    "        self.case_paths = case_paths\n",
    "        self.name = name\n",
    "        self.n_cases = len(case_paths)\n",
    "        \n",
    "        # Load cases into NumPy cache (NOT JAX)\n",
    "        print(f'Building {name} cache: {self.n_cases} cases...')\n",
    "        self.cache = []\n",
    "        for i, cp in enumerate(case_paths):\n",
    "            if i % 20 == 0 and i > 0:\n",
    "                print(f'  Loaded {i}/{self.n_cases}...')\n",
    "            mods, seg = load_case(cp)\n",
    "            self.cache.append({\n",
    "                'mods': mods,  # Keep as NumPy float32\n",
    "                'seg': seg      # Keep as NumPy int16\n",
    "            })\n",
    "        \n",
    "        # Get metadata from first case\n",
    "        self.vol_shape = self.cache[0]['mods'].shape[1:]  # (H, W, D)\n",
    "        self.n_modalities = self.cache[0]['mods'].shape[0]  # M\n",
    "        \n",
    "        # Estimate memory usage\n",
    "        bytes_per_case = self.cache[0]['mods'].nbytes + self.cache[0]['seg'].nbytes\n",
    "        total_gb = (bytes_per_case * self.n_cases) / 1e9\n",
    "        print(f'{name} complete: {self.n_cases} cases, {total_gb:.2f} GB')\n",
    "    \n",
    "    def sample_voxels(self, case_indices, h_coords, w_coords, d_coords):\n",
    "        \"\"\"\n",
    "        Gather specific voxels from cache\n",
    "        \n",
    "        Args:\n",
    "            case_indices: (N,) which cases to sample from\n",
    "            h_coords, w_coords, d_coords: (N,) spatial coordinates\n",
    "            \n",
    "        Returns:\n",
    "            mods: (N, M) modality intensities as NumPy\n",
    "            segs: (N,) segmentation labels as NumPy\n",
    "        \"\"\"\n",
    "        N = len(case_indices)\n",
    "        M = self.n_modalities\n",
    "        \n",
    "        mods_out = np.zeros((N, M), dtype=np.float32)\n",
    "        segs_out = np.zeros(N, dtype=np.int16)\n",
    "        \n",
    "        for i in range(N):\n",
    "            c_idx = case_indices[i]\n",
    "            h, w, d = h_coords[i], w_coords[i], d_coords[i]\n",
    "            mods_out[i] = self.cache[c_idx]['mods'][:, h, w, d]\n",
    "            segs_out[i] = self.cache[c_idx]['seg'][h, w, d]\n",
    "        \n",
    "        return mods_out, segs_out\n",
    "\n",
    "# Build streaming caches (NumPy only, not JAX!)\n",
    "train_cache = StreamingBraTSCache(train_cases, name=\"train\")\n",
    "val_cache = StreamingBraTSCache(val_cases, name=\"val\") if val_cases else None\n",
    "\n",
    "# Extract metadata\n",
    "vol_shape = train_cache.vol_shape\n",
    "H, W, D = vol_shape\n",
    "M = train_cache.n_modalities\n",
    "C = train_cache.n_cases  # Number of training cases\n",
    "\n",
    "print(f'Volume shape (H,W,D): {vol_shape}')\n",
    "print(f'Train cases: {C} | Val cases: {len(val_cases) if val_cases else 0}')\n",
    "print(f'Modalities: {M}')\n",
    "\n",
    "# Log volume info to W&B\n",
    "wandb.config.update({\n",
    "    \"volume_shape\": vol_shape,\n",
    "    \"num_modalities\": M,\n",
    "})\n",
    "\n",
    "# ============================================================================\n",
    "# Streaming Batch Sampler - samples and converts to JAX on-the-fly\n",
    "# ============================================================================\n",
    "\n",
    "def sample_batch(rng_key, batch_size, cache=train_cache):\n",
    "    \"\"\"\n",
    "    Sample random voxels from random cases using streaming\n",
    "    \n",
    "    Returns JAX arrays ready for training\n",
    "    \"\"\"\n",
    "    key_case, key_x, key_y, key_z = jax.random.split(rng_key, 4)\n",
    "    \n",
    "    # Sample random indices (on CPU)\n",
    "    ci = jax.random.randint(key_case, (batch_size,), 0, cache.n_cases)\n",
    "    xs = jax.random.randint(key_x, (batch_size,), 0, H)\n",
    "    ys = jax.random.randint(key_y, (batch_size,), 0, W)\n",
    "    zs = jax.random.randint(key_z, (batch_size,), 0, D)\n",
    "    \n",
    "    # Convert to NumPy for gathering (JAX -> NumPy is cheap)\n",
    "    ci_np = np.array(ci)\n",
    "    xs_np = np.array(xs)\n",
    "    ys_np = np.array(ys)\n",
    "    zs_np = np.array(zs)\n",
    "    \n",
    "    # Gather voxels from NumPy cache\n",
    "    intens_np, labels_np = cache.sample_voxels(ci_np, xs_np, ys_np, zs_np)\n",
    "    \n",
    "    # Build coordinates\n",
    "    coords = jnp.stack([xs, ys, zs], axis=-1)\n",
    "    norm_coords = (coords / jnp.array([H-1, W-1, D-1])) * 2.0 - 1.0\n",
    "    \n",
    "    # Convert gathered data to JAX (only the batch!)\n",
    "    intens = jnp.array(intens_np)\n",
    "    labels = jnp.array(labels_np, dtype=jnp.int32)\n",
    "    \n",
    "    return norm_coords, intens, labels\n",
    "\n",
    "# Test the streaming sampler\n",
    "test_coords, test_feats, test_labels = sample_batch(jax_key, 4)\n",
    "print('Sample coords', test_coords.shape, 'feats', test_feats.shape, 'labels', test_labels.shape)\n",
    "print('âœ“ Streaming sampler working!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761044d9",
   "metadata": {},
   "source": [
    "## Fourier Feature Mapping\n",
    "We map 3D coordinates (normalized) to a higher-dimensional space using sinusoidal functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf624396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_features(coords: jnp.ndarray, k: int) -> jnp.ndarray:\n",
    "    # coords: (B,3) in [-1,1]\n",
    "    B, dim = coords.shape\n",
    "    freqs = jnp.arange(1, k+1)  # (k,)\n",
    "    # shape (B, dim, k)\n",
    "    ang = coords[..., None] * freqs[None, None, :] * math.pi\n",
    "    sin = jnp.sin(ang); cos = jnp.cos(ang)\n",
    "    ff = jnp.concatenate([sin, cos], axis=-1).reshape(B, dim * 2 * k)\n",
    "    return ff\n",
    "\n",
    "def build_input(coords, intensities):\n",
    "    ff = fourier_features(coords, FOURIER_FREQS)\n",
    "    return jnp.concatenate([coords, ff, intensities], axis=-1)\n",
    "\n",
    "in_dim_test = build_input(test_coords, test_feats).shape[-1]\n",
    "print('Input dim:', in_dim_test)\n",
    "\n",
    "# Log model architecture to W&B\n",
    "wandb.config.update({\"input_dim\": in_dim_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e3b3a",
   "metadata": {},
   "source": [
    "## MLP Definition (Pure Functions)\n",
    "We define simple MLP parameter initialization and forward apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glorot(key, shape):\n",
    "    fan_in, fan_out = shape[0], shape[1]\n",
    "    limit = math.sqrt(6.0 / (fan_in + fan_out))\n",
    "    return jax.random.uniform(key, shape, minval=-limit, maxval=limit)\n",
    "\n",
    "def init_mlp(key, in_dim, hidden_dims, out_dim):\n",
    "    params = []\n",
    "    dims = [in_dim] + hidden_dims + [out_dim]\n",
    "    for i in range(len(dims)-1):\n",
    "        key, k1, k2 = jax.random.split(key, 3)\n",
    "        W = glorot(k1, (dims[i], dims[i+1]))\n",
    "        b = jnp.zeros((dims[i+1],))\n",
    "        params.append({'W': W, 'b': b})\n",
    "    return key, params\n",
    "\n",
    "def apply_mlp(params, x):\n",
    "    *hidden, last = params\n",
    "    h = x\n",
    "    for layer in hidden:\n",
    "        h = jnp.dot(h, layer['W']) + layer['b']\n",
    "        h = jax.nn.relu(h)\n",
    "    out = jnp.dot(h, last['W']) + last['b']\n",
    "    return out  # logits\n",
    "\n",
    "# Initialize model\n",
    "jax_key, params = init_mlp(jax_key, in_dim_test, HIDDEN_DIMS, NUM_CLASSES)\n",
    "sum_params = sum(p['W'].size + p['b'].size for p in params)\n",
    "print('Total parameters:', sum_params)\n",
    "\n",
    "# Log model info to W&B\n",
    "wandb.config.update({\"total_parameters\": sum_params})\n",
    "wandb.run.summary[\"model_parameters\"] = sum_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afced0",
   "metadata": {},
   "source": [
    "## Loss, Optimizer, and Training Step\n",
    "We use cross-entropy loss with Optax Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96bdc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer, loss, microbatch step (with per-class metrics)\n",
    "schedule = optax.warmup_cosine_decay_schedule(init_value=0.0, peak_value=LR, warmup_steps=WARMUP_STEPS, decay_steps=max(1, TRAIN_STEPS-WARMUP_STEPS), end_value=MIN_LR)\n",
    "optimizer = optax.chain(optax.clip_by_global_norm(CLIP_NORM), optax.adamw(schedule))\n",
    "opt_state = optimizer.init(params)\n",
    "cw = jnp.array(CLASS_WEIGHTS)\n",
    "\n",
    "def one_hot(labels, num_classes):\n",
    "    return jax.nn.one_hot(labels, num_classes)\n",
    "\n",
    "def soft_dice_per_class(probs, onehot, eps=1e-6):\n",
    "    inter = jnp.sum(probs * onehot, axis=0)\n",
    "    sums = jnp.sum(probs, axis=0) + jnp.sum(onehot, axis=0)\n",
    "    dice_k = (2*inter + eps) / (sums + eps)\n",
    "    return dice_k\n",
    "\n",
    "def loss_fn(params, coords, intensities, labels):\n",
    "    x = build_input(coords, intensities)\n",
    "    logits = apply_mlp(params, x)\n",
    "    y = one_hot(labels, NUM_CLASSES)\n",
    "    ce_vec = optax.softmax_cross_entropy(logits, y)  # (N,)\n",
    "    # Weighted scalar CE for training\n",
    "    w = jnp.take(cw, labels)\n",
    "    ce_scalar = (ce_vec * w).mean()\n",
    "    # Dice term for training\n",
    "    if DICE_WEIGHT>0:\n",
    "        probs = jax.nn.softmax(logits, axis=-1)\n",
    "        dice_k = soft_dice_per_class(probs, y)  # (K,)\n",
    "        dice_mean = dice_k.mean()\n",
    "        loss = (1-DICE_WEIGHT)*ce_scalar + DICE_WEIGHT*(1-dice_mean)\n",
    "    else:\n",
    "        probs = jax.nn.softmax(logits, axis=-1)\n",
    "        dice_k = soft_dice_per_class(probs, y)\n",
    "        loss = ce_scalar\n",
    "    # Per-class CE (unweighted) for reporting\n",
    "    counts = jnp.sum(y, axis=0)  # (K,)\n",
    "    ce_sum_k = jnp.sum(ce_vec[:, None] * y, axis=0)\n",
    "    ce_mean_k = ce_sum_k / jnp.maximum(counts, 1.0)\n",
    "    aux = {\n",
    "        'ce_per_class': ce_mean_k,\n",
    "        'dice_per_class': dice_k,\n",
    "    }\n",
    "    return loss, aux\n",
    "\n",
    "loss_and_grad = jax.jit(jax.value_and_grad(loss_fn, has_aux=True))\n",
    "\n",
    "def microbatch_step(params, opt_state, rng_key):\n",
    "    grads_acc = [ {'W': jnp.zeros_like(p['W']), 'b': jnp.zeros_like(p['b'])} for p in params ]\n",
    "    loss_acc = 0.0\n",
    "    ce_pc_acc = jnp.zeros((NUM_CLASSES,))\n",
    "    dice_pc_acc = jnp.zeros((NUM_CLASSES,))\n",
    "    key = rng_key\n",
    "    for _ in range(ACCUM_STEPS):\n",
    "        key, sub = jax.random.split(key)\n",
    "        coords, feats, labels = sample_batch(sub, MICRO_BATCH_SIZE)\n",
    "        (loss_val, aux), grads = loss_and_grad(params, coords, feats, labels)\n",
    "        loss_acc += float(loss_val)\n",
    "        ce_pc_acc = ce_pc_acc + aux['ce_per_class']\n",
    "        dice_pc_acc = dice_pc_acc + aux['dice_per_class']\n",
    "        grads_acc = [ {'W': ga['W']+g['W'], 'b': ga['b']+g['b']} for ga,g in zip(grads_acc, grads) ]\n",
    "    grads_mean = [ {'W': g['W']/ACCUM_STEPS, 'b': g['b']/ACCUM_STEPS} for g in grads_acc ]\n",
    "    updates, opt_state = optimizer.update(grads_mean, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    aux_mean = {\n",
    "        'ce_per_class': ce_pc_acc/ACCUM_STEPS,\n",
    "        'dice_per_class': dice_pc_acc/ACCUM_STEPS,\n",
    "    }\n",
    "    return params, opt_state, loss_acc/ACCUM_STEPS, aux_mean\n",
    "\n",
    "# Warm-up\n",
    "jax_key, warm_key = jax.random.split(jax_key)\n",
    "params, opt_state, warm_loss, warm_aux = microbatch_step(params, opt_state, warm_key)\n",
    "print('Warm-up loss', warm_loss)\n",
    "# Log warm-up info to W&B\n",
    "wandb.log({\"warmup/loss\": warm_loss,}, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff0ac7",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "We iterate for a small number of steps (increase TRAIN_STEPS for better results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_history = []\n",
    "dice_history = [[] for _ in range(NUM_CLASSES)]\n",
    "ce_history = [[] for _ in range(NUM_CLASSES)]\n",
    "start = time.time()\n",
    "\n",
    "# Get dimensions from cache instead of train_mods\n",
    "H, W, D = vol_shape  # We set this in the previous cell\n",
    "mid_z = D // 2\n",
    "\n",
    "# ============================================================================\n",
    "# Slice prediction helper - UPDATED for streaming\n",
    "# ============================================================================\n",
    "\n",
    "def predict_slice(params, case_index=0, z=mid_z, cache=train_cache):\n",
    "    \"\"\"\n",
    "    Predict segmentation for a 2D slice from a cached case\n",
    "    \n",
    "    Args:\n",
    "        params: Model parameters\n",
    "        case_index: Which case in the cache (0 to cache.n_cases-1)\n",
    "        z: Which z-slice to predict\n",
    "        cache: StreamingBraTSCache to use (train_cache or val_cache)\n",
    "    \"\"\"\n",
    "    # Create coordinate grid for the slice\n",
    "    xs = jnp.arange(H)\n",
    "    ys = jnp.arange(W)\n",
    "    X, Y = jnp.meshgrid(xs, ys, indexing='ij')  # (H, W)\n",
    "    x_flat = X.reshape(-1)\n",
    "    y_flat = Y.reshape(-1)\n",
    "    z_flat = jnp.full_like(x_flat, z)\n",
    "    \n",
    "    # Normalize coordinates\n",
    "    coords = jnp.stack([x_flat, y_flat, z_flat], axis=-1)\n",
    "    norm_coords = (coords / jnp.array([H-1, W-1, D-1])) * 2.0 - 1.0\n",
    "    \n",
    "    # Gather intensities from cache (NumPy)\n",
    "    x_np = np.array(x_flat)\n",
    "    y_np = np.array(y_flat)\n",
    "    z_np = np.full(len(x_flat), z, dtype=np.int32)\n",
    "    case_indices = np.full(len(x_flat), case_index, dtype=np.int32)\n",
    "    \n",
    "    intens_np, _ = cache.sample_voxels(case_indices, x_np, y_np, z_np)\n",
    "    intens = jnp.array(intens_np)  # (H*W, M)\n",
    "    \n",
    "    # Build input and predict\n",
    "    x_in = build_input(norm_coords, intens)\n",
    "    logits = apply_mlp(params, x_in)\n",
    "    pred = jnp.argmax(logits, axis=-1)\n",
    "    \n",
    "    return pred.reshape(H, W)\n",
    "\n",
    "# ============================================================================\n",
    "# Cache ground truth slice for visualization\n",
    "# ============================================================================\n",
    "\n",
    "# Pick a validation case for visualization (or train if no val)\n",
    "vis_cache = val_cache if val_cache else train_cache\n",
    "VIS_CASE_INDEX = 0  # First case in the visualization cache\n",
    "\n",
    "# Extract ground truth slice and modality slice from cache\n",
    "true_slice = vis_cache.cache[VIS_CASE_INDEX]['seg'][:, :, mid_z]\n",
    "mod0_slice = vis_cache.cache[VIS_CASE_INDEX]['mods'][0, :, :, mid_z]\n",
    "\n",
    "print(f\"Visualizing case {VIS_CASE_INDEX} from {'validation' if val_cache else 'training'} set\")\n",
    "print(f\"Slice shape: {true_slice.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Training Loop\n",
    "# ============================================================================\n",
    "\n",
    "for step in range(1, TRAIN_STEPS + 1):\n",
    "    jax_key, step_key = jax.random.split(jax_key)\n",
    "    params, opt_state, loss_val, aux = microbatch_step(params, opt_state, step_key)\n",
    "    loss_history.append(float(loss_val))\n",
    "    dice_k = aux['dice_per_class']\n",
    "    ce_k = aux['ce_per_class']\n",
    "    \n",
    "    # Prepare W&B metrics\n",
    "    wandb_metrics = {\n",
    "        \"train/loss\": float(loss_val),\n",
    "        \"train/step\": step,\n",
    "    }\n",
    "    \n",
    "    # Per-class metrics\n",
    "    for k in range(NUM_CLASSES):\n",
    "        dice_history[k].append(float(dice_k[k]))\n",
    "        ce_history[k].append(float(ce_k[k]))\n",
    "        wandb_metrics[f\"train/dice_class_{k}\"] = float(dice_k[k])\n",
    "        wandb_metrics[f\"train/ce_class_{k}\"] = float(ce_k[k])\n",
    "    \n",
    "    # Mean metrics\n",
    "    wandb_metrics[\"train/dice_mean\"] = float(dice_k.mean())\n",
    "    wandb_metrics[\"train/ce_mean\"] = float(ce_k.mean())\n",
    "    \n",
    "    # Log to W&B\n",
    "    wandb.log(wandb_metrics, step=step)\n",
    "\n",
    "    if step % 25 == 0 or step == 1:\n",
    "        # Predict single slice from visualization case\n",
    "        pred_slice = predict_slice(params, case_index=VIS_CASE_INDEX, cache=vis_cache)\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "        \n",
    "        # Loss + per-class dice\n",
    "        ax0 = axes[0]\n",
    "        ax0.plot(loss_history, color='blue', label='Loss')\n",
    "        ax0.set_title('Loss, Dice (by class), CE (latest)')\n",
    "        ax0.set_xlabel('Step')\n",
    "        ax0.set_ylabel('Loss')\n",
    "        \n",
    "        ax1 = ax0.twinx()\n",
    "        colors = plt.cm.tab10.colors\n",
    "        latest_ce = [h[-1] if h else float('nan') for h in ce_history]\n",
    "        for k in range(NUM_CLASSES):\n",
    "            ax1.plot(dice_history[k], label=f'Dice c{k}', color=colors[k % len(colors)])\n",
    "        ax1.set_ylabel('Dice')\n",
    "        \n",
    "        # Add CE per-class as text box\n",
    "        ce_text = 'CE per class: ' + ', '.join([f'c{k}:{latest_ce[k]:.3f}' for k in range(NUM_CLASSES)])\n",
    "        ax0.text(0.02, 0.02, ce_text, transform=ax0.transAxes, fontsize=8, \n",
    "                va='bottom', ha='left', bbox=dict(facecolor='white', alpha=0.6, edgecolor='none'))\n",
    "        \n",
    "        # Combine legends\n",
    "        lines0, labels0 = ax0.get_legend_handles_labels()\n",
    "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "        ax0.legend(lines0 + lines1, labels0 + labels1, loc='upper right', fontsize=8)\n",
    "        \n",
    "        # Ground truth image\n",
    "        axes[1].imshow(mod0_slice, cmap='gray')\n",
    "        axes[1].imshow(true_slice, alpha=0.35, cmap='tab10')\n",
    "        axes[1].set_title('Ground Truth Slice')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Prediction image\n",
    "        axes[2].imshow(mod0_slice, cmap='gray')\n",
    "        axes[2].imshow(pred_slice, alpha=0.35, cmap='tab10')\n",
    "        axes[2].set_title(f'Pred Slice Step {step}')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        fig.suptitle(f'Step {step}/{TRAIN_STEPS} Loss={loss_val:.4f}')\n",
    "        plt.tight_layout()\n",
    "        display(fig)\n",
    "        \n",
    "        # Log figure to W&B\n",
    "        wandb.log({\"train/predictions\": wandb.Image(fig)}, step=step)\n",
    "        plt.close(fig)\n",
    "\n",
    "training_time = time.time() - start\n",
    "print(f'Training time: {training_time:.2f}s')\n",
    "wandb.run.summary[\"training_time_seconds\"] = training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5efd2c5",
   "metadata": {},
   "source": [
    "## Evaluation (Reconstruct Full Segmentation for One Case)\n",
    "We reconstruct the segmentation by querying the model on all voxel coordinates of the validation case (chosen by VAL_CASE_INDEX). Then compute Dice per class. To avoid memory overflow, we chunk coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89253c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_volume(params, case_data, chunk=200000):\n",
    "    \"\"\"\n",
    "    Predict segmentation for an entire 3D volume\n",
    "    \n",
    "    Args:\n",
    "        case_data: Dict with 'mods' and 'seg' as NumPy arrays\n",
    "    \"\"\"\n",
    "    mods = case_data['mods']  # (M, H, W, D)\n",
    "    seg_true = case_data['seg']  # (H, W, D)\n",
    "    M, H, W, D = mods.shape\n",
    "    \n",
    "    # Build coordinate grid\n",
    "    xs, ys, zs = np.arange(H), np.arange(W), np.arange(D)\n",
    "    grid = np.stack(np.meshgrid(xs, ys, zs, indexing='ij'), axis=-1).reshape(-1, 3)  # (N, 3)\n",
    "    intens = mods.transpose(1, 2, 3, 0).reshape(-1, M)  # Align with grid\n",
    "    \n",
    "    # Normalize coords\n",
    "    norm_coords = (grid / np.array([H-1, W-1, D-1])) * 2.0 - 1.0\n",
    "    \n",
    "    # Predict in chunks to avoid OOM\n",
    "    preds = []\n",
    "    for i in range(0, len(grid), chunk):\n",
    "        c_chunk = jnp.array(norm_coords[i:i+chunk])\n",
    "        f_chunk = jnp.array(intens[i:i+chunk])\n",
    "        x_in = build_input(c_chunk, f_chunk)\n",
    "        logits = apply_mlp(params, x_in)\n",
    "        cls = jnp.argmax(logits, axis=-1)\n",
    "        preds.append(np.array(cls, dtype=np.int16))\n",
    "    \n",
    "    pred_flat = np.concatenate(preds, axis=0)\n",
    "    pred_vol = pred_flat.reshape(H, W, D)\n",
    "    \n",
    "    return pred_vol, seg_true\n",
    "\n",
    "def dice_score(pred, true, num_classes):\n",
    "    \"\"\"Calculate Dice score for each class\"\"\"\n",
    "    scores = {}\n",
    "    for c in range(num_classes):\n",
    "        pred_c = (pred == c)\n",
    "        true_c = (true == c)\n",
    "        inter = (pred_c & true_c).sum()\n",
    "        denom = pred_c.sum() + true_c.sum()\n",
    "        dice = (2*inter + 1e-6) / (denom + 1e-6) if denom > 0 else np.nan\n",
    "        scores[c] = dice\n",
    "    return scores\n",
    "\n",
    "# ============================================================================\n",
    "# Choose a validation case - UPDATED for StreamingBraTSCache\n",
    "# ============================================================================\n",
    "\n",
    "if val_cache and val_cache.n_cases > 0:\n",
    "    # Use validation set\n",
    "    case_index = min(VAL_CASE_INDEX, val_cache.n_cases - 1)\n",
    "    chosen_case = val_cache.cache[case_index]\n",
    "    chosen_set = 'validation'\n",
    "    print(f\"Evaluating on validation case {case_index}/{val_cache.n_cases}\")\n",
    "else:\n",
    "    # Fallback to training set\n",
    "    case_index = min(VAL_CASE_INDEX, train_cache.n_cases - 1)\n",
    "    chosen_case = train_cache.cache[case_index]\n",
    "    chosen_set = 'training'\n",
    "    print(f\"Evaluating on training case {case_index}/{train_cache.n_cases}\")\n",
    "\n",
    "# Predict full volume\n",
    "print(f\"Predicting full volume (shape: {chosen_case['mods'].shape})...\")\n",
    "pred_vol, true_vol = predict_volume(params, chosen_case, chunk=120000)\n",
    "\n",
    "# Calculate Dice scores\n",
    "scores = dice_score(pred_vol, true_vol, NUM_CLASSES)\n",
    "print(f'Dice scores ({chosen_set} set):', {k: f\"{v:.4f}\" for k, v in scores.items()})\n",
    "\n",
    "# Log validation dice scores to W&B\n",
    "val_metrics = {f\"val/dice_class_{c}\": score for c, score in scores.items()}\n",
    "val_metrics[\"val/dice_mean\"] = np.nanmean(list(scores.values()))\n",
    "wandb.log(val_metrics)\n",
    "wandb.run.summary.update(val_metrics)\n",
    "\n",
    "print(f\"Mean Dice: {val_metrics['val/dice_mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46607348",
   "metadata": {},
   "source": [
    "## Visualization (Middle Slices)\n",
    "We show all modalities with ground-truth and predicted segmentation overlays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ef75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mid_z = pred_vol.shape[2]//2\n",
    "import numpy as _np\n",
    "\n",
    "def _dice_macro_slice(pred2d, true2d, num_classes=4):\n",
    "    scores = []\n",
    "    for c in range(num_classes):\n",
    "        p = (pred2d == c)\n",
    "        t = (true2d == c)\n",
    "        inter = (p & t).sum()\n",
    "        denom = p.sum() + t.sum()\n",
    "        if denom > 0:\n",
    "            scores.append((2*inter + 1e-6) / (denom + 1e-6))\n",
    "    return float(_np.mean(scores)) if len(scores)>0 else float('nan')\n",
    "\n",
    "def _psnr_slice(pred2d, true2d, max_val=3.0):\n",
    "    mse = _np.mean((_np.asarray(pred2d, dtype=_np.float32) - _np.asarray(true2d, dtype=_np.float32))**2)\n",
    "    if mse <= 1e-12:\n",
    "        return float('inf')\n",
    "    return float(10.0 * _np.log10((max_val*max_val) / (mse + 1e-12)))\n",
    "\n",
    "def visualize_modalities_with_overlays(mods, seg_gt, seg_pred, z):\n",
    "    M = mods.shape[0]\n",
    "    fig, axes = plt.subplots(2, M, figsize=(3*M, 6))\n",
    "    if M == 1:\n",
    "        axes = _np.array([[axes[0]],[axes[1]]], dtype=object)\n",
    "    for m in range(M):\n",
    "        ax_gt = axes[0, m]\n",
    "        ax_pred = axes[1, m]\n",
    "        # Ground truth overlay\n",
    "        ax_gt.imshow(mods[m,:,:,z], cmap='gray')\n",
    "        ax_gt.imshow(seg_gt[:,:,z], cmap='tab10', alpha=0.35, vmin=0, vmax=3)\n",
    "        ax_gt.set_title(f'Mod {m} + GT', fontsize=10)\n",
    "        ax_gt.axis('off')\n",
    "        # Prediction overlay with metrics annotation box\n",
    "        ax_pred.imshow(mods[m,:,:,z], cmap='gray')\n",
    "        ax_pred.imshow(seg_pred[:,:,z], cmap='tab10', alpha=0.35, vmin=0, vmax=3)\n",
    "        d = _dice_macro_slice(seg_pred[:,:,z], seg_gt[:,:,z], num_classes=4)\n",
    "        p = _psnr_slice(seg_pred[:,:,z], seg_gt[:,:,z], max_val=3.0)\n",
    "        ax_pred.set_title(f'Mod {m} + Pred', fontsize=10)\n",
    "        ax_pred.text(0.01, 0.99, f'Dice {d:.3f} PSNR {p:.2f} dB',\n",
    "                   transform=ax_pred.transAxes, ha='left', va='top', fontsize=8,\n",
    "                   color='yellow', bbox=dict(boxstyle='round', fc='black', alpha=0.5, pad=0.4))\n",
    "        ax_pred.axis('off')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Show current validation case slice with metrics (non-overlapping)\n",
    "fig = visualize_modalities_with_overlays(chosen_case['mods'], true_vol, pred_vol, mid_z)\n",
    "plt.show()\n",
    "\n",
    "# Log validation visualization to W&B\n",
    "wandb.log({\"val/segmentation_overlay\": wandb.Image(fig)})\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3f8f6",
   "metadata": {},
   "source": [
    "## Save Parameters\n",
    "We save learned parameters for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0075a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_params = {}\n",
    "for i, layer in enumerate(params):\n",
    "    flat_params[f'W_{i}'] = np.array(layer['W'])\n",
    "    flat_params[f'b_{i}'] = np.array(layer['b'])\n",
    "\n",
    "SAVE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "np.savez_compressed(SAVE_PATH, **flat_params)\n",
    "print('Saved parameters to', SAVE_PATH)\n",
    "\n",
    "# Create W&B artifact for model parameters\n",
    "artifact = wandb.Artifact(\n",
    "    name=f\"inr-model-fold{FOLD_INDEX}\",\n",
    "    type=\"model\",\n",
    "    description=f\"Fourier Feature INR trained on BraTS 2023, fold {FOLD_INDEX}\",\n",
    "    metadata={\n",
    "        \"fold_index\": FOLD_INDEX,\n",
    "        \"train_steps\": TRAIN_STEPS,\n",
    "        \"final_loss\": loss_history[-1] if loss_history else None,\n",
    "        \"val_dice_mean\": val_metrics.get(\"val/dice_mean\") if 'val_metrics' in locals() else None,\n",
    "        \"architecture\": {\n",
    "            \"input_dim\": in_dim_test,\n",
    "            \"hidden_dims\": HIDDEN_DIMS,\n",
    "            \"num_classes\": NUM_CLASSES,\n",
    "            \"fourier_freqs\": FOURIER_FREQS,\n",
    "        }\n",
    "    }\n",
    ")\n",
    "artifact.add_file(str(SAVE_PATH))\n",
    "wandb.log_artifact(artifact)\n",
    "print(f\"Logged model artifact to W&B: {artifact.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6974ec57",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Increase TRAIN_STEPS, CASE_LIMIT for better accuracy.\n",
    "- Add class rebalancing or focal loss (BraTS class imbalance).\n",
    "- Integrate data augmentations (intensity shifts, coordinate jitter).\n",
    "- Compare against nnU-Net baseline metrics.\n",
    "- Explore multi-resolution coordinate conditioning or SIREN activations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c814a",
   "metadata": {},
   "source": [
    "## Hold-Out Case Evaluation\n",
    "We evaluate the model on a case not included in the training subset (beyond CASE_LIMIT). If unavailable, we skip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ae923",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases_full = find_cases(DATA_ROOT)\n",
    "extra_cases = all_cases_full[CASE_LIMIT:]\n",
    "print('Hold-out cases available:', len(extra_cases))\n",
    "\n",
    "if len(extra_cases) > 0:\n",
    "    hold_case_path = extra_cases[1]\n",
    "    hold_mods, hold_seg = load_case(hold_case_path)\n",
    "    hold_case_data = {'mods': hold_mods, 'seg': hold_seg}\n",
    "    hold_pred, hold_true = predict_volume(params, hold_case_data, chunk=120000)\n",
    "    hold_scores = dice_score(hold_pred, hold_true, NUM_CLASSES)\n",
    "    print('Hold-out Dice:', hold_scores)\n",
    "    \n",
    "    # Log hold-out metrics to W&B\n",
    "    holdout_metrics = {f\"holdout/dice_class_{c}\": score for c, score in hold_scores.items()}\n",
    "    holdout_metrics[\"holdout/dice_mean\"] = np.nanmean(list(hold_scores.values()))\n",
    "    wandb.log(holdout_metrics)\n",
    "    wandb.run.summary.update(holdout_metrics)\n",
    "    \n",
    "    mid_z_hold = hold_pred.shape[2]//2\n",
    "    fig = visualize_modalities_with_overlays(hold_mods, hold_true, hold_pred, mid_z_hold)\n",
    "    plt.show()\n",
    "    \n",
    "    # Log hold-out visualization to W&B\n",
    "    wandb.log({\"holdout/segmentation_overlay\": wandb.Image(fig)})\n",
    "    plt.close(fig)\n",
    "else:\n",
    "    print('No hold-out case beyond training CASE_LIMIT to evaluate.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edcd918",
   "metadata": {},
   "source": [
    "## Interactive Viewer (Hold-outs)\n",
    "Use the dropdown to select a hold-out case and slider to browse slices. The layout (all modalities with GT and Pred overlays) remains fixed; only the slice changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import pathlib as _pl\n",
    "\n",
    "# Prepare hold-out cases list\n",
    "all_cases_full = find_cases(DATA_ROOT)\n",
    "extra_cases = all_cases_full[CASE_LIMIT:]\n",
    "case_options = [(p.name, str(p)) for p in extra_cases]\n",
    "print('Hold-out cases:', len(case_options))\n",
    "\n",
    "hold_pred_cache = {}  # path -> pred volume\n",
    "state = {'mods': None, 'true': None, 'pred': None}\n",
    "\n",
    "def load_and_predict_cached(case_path_str):\n",
    "    p = _pl.Path(case_path_str)\n",
    "    mods, seg = load_case(p)\n",
    "    if case_path_str not in hold_pred_cache:\n",
    "        pred, _ = predict_volume(params, {'mods': mods, 'seg': seg}, chunk=120000)\n",
    "        hold_pred_cache[case_path_str] = pred\n",
    "    return mods, seg, hold_pred_cache[case_path_str]\n",
    "\n",
    "out = widgets.Output()\n",
    "if len(case_options) == 0:\n",
    "    print('No hold-out cases available to visualize.')\n",
    "else:\n",
    "    dd_hold = widgets.Dropdown(options=case_options, description='Hold-out:')\n",
    "    # Initialize\n",
    "    state['mods'], state['true'], state['pred'] = load_and_predict_cached(dd_hold.value)\n",
    "    z_slider = widgets.IntSlider(min=0, max=int(state['pred'].shape[2]-1), value=int(state['pred'].shape[2]//2), description='Slice z')\n",
    "\n",
    "    def render_slice(z):\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            fig = visualize_modalities_with_overlays(state['mods'], state['true'], state['pred'], int(z))\n",
    "            plt.show()\n",
    "            plt.close(fig)\n",
    "\n",
    "    def on_slice_change(change):\n",
    "        render_slice(change['new'])\n",
    "\n",
    "    def on_case_change(change):\n",
    "        state['mods'], state['true'], state['pred'] = load_and_predict_cached(change['new'])\n",
    "        z_slider.max = int(state['pred'].shape[2]-1)\n",
    "        z_slider.value = int(state['pred'].shape[2]//2)\n",
    "        \n",
    "        # Log explored case to W&B\n",
    "        case_name = _pl.Path(change['new']).name\n",
    "        case_scores = dice_score(state['pred'], state['true'], NUM_CLASSES)\n",
    "        case_metrics = {\n",
    "            f\"interactive/{case_name}/dice_class_{c}\": score \n",
    "            for c, score in case_scores.items()\n",
    "        }\n",
    "        case_metrics[f\"interactive/{case_name}/dice_mean\"] = np.nanmean(list(case_scores.values()))\n",
    "        wandb.log(case_metrics)\n",
    "        \n",
    "        render_slice(z_slider.value)\n",
    "\n",
    "    z_slider.observe(on_slice_change, names='value')\n",
    "    dd_hold.observe(on_case_change, names='value')\n",
    "    display(widgets.VBox([dd_hold, z_slider, out]))\n",
    "    render_slice(z_slider.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b68bc-83a0-4194-9658-579d5cb50eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis6020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
