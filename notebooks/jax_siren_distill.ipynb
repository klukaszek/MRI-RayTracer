{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SIREN INR for BraTS 2023 with Optional CNN Distillation (JAX)\n",
        "\n",
        "This notebook implements a SIREN-based implicit neural representation (INR) for voxel-wise segmentation. It supports standard CE/Dice training and optional knowledge distillation from a CNN teacher (e.g., nnU-Net) by loading per-voxel soft targets/logits if available.\n",
        "\n",
        "Notes:\n",
        "- SIREN uses sinusoidal activations enabling high-frequency signal fitting.\n",
        "- We combine coordinates + multi-modal intensities as input.\n",
        "- For distillation, provide teacher per-voxel logits as NIfTI or NPZ tensors aligned with the target volume.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Devices: [CpuDevice(id=0)] accum 16\n"
          ]
        }
      ],
      "source": [
        "import os, math, pathlib, time\n",
        "from typing import Dict, Tuple, Optional\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import jax, jax.numpy as jnp\n",
        "import optax\n",
        "\n",
        "DATA_ROOT = pathlib.Path('../data/BraTS-2023')\n",
        "SAVE_PATH = pathlib.Path('../artifacts/inr_siren_brats23.npz')\n",
        "CASE_LIMIT = 16\n",
        "GLOBAL_BATCH = 32768\n",
        "MICRO_BATCH = 2048\n",
        "SIREN_HIDDEN = [256,256,256,256]\n",
        "OMEGA_0 = 30.0  # SIREN frequency scale for first layer\n",
        "OMEGA = 30.0    # subsequent layers\n",
        "LR = 2e-3; MIN_LR=2e-4; WARMUP=50; STEPS=600\n",
        "NUM_CLASSES = 4\n",
        "RNG_SEED = 123\n",
        "KD_WEIGHT = 0.3  # weight for distillation (0 disables KD)\n",
        "TEACHER_DIR = pathlib.Path('artifacts/teacher_logits')  # optional\n",
        "\n",
        "key = jax.random.PRNGKey(RNG_SEED)\n",
        "ACCUM = (GLOBAL_BATCH + MICRO_BATCH - 1)//MICRO_BATCH\n",
        "print('Devices:', jax.devices(), 'accum', ACCUM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/BraTS-2023'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m     seg = nib.load(\u001b[38;5;28mstr\u001b[39m(p/\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEG\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.nii.gz\u001b[39m\u001b[33m'\u001b[39m)).get_fdata().astype(np.int16)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.stack(mods,\u001b[32m0\u001b[39m), seg\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m cases = \u001b[43mfind_cases\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_ROOT\u001b[49m\u001b[43m)\u001b[49m[:CASE_LIMIT]\n\u001b[32m     15\u001b[39m mods0, seg0 = load_case(cases[\u001b[32m0\u001b[39m])\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mVol shape:\u001b[39m\u001b[33m'\u001b[39m, mods0.shape, seg0.shape)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mfind_cases\u001b[39m\u001b[34m(root)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_cases\u001b[39m(root: pathlib.Path):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m p.is_dir() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m((p/\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.nii.gz\u001b[39m\u001b[33m'\u001b[39m).exists() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MODS)]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/pathlib.py:931\u001b[39m, in \u001b[36mPath.iterdir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    928\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Iterate over the files in this directory.  Does not yield any\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[33;03m    result for the special paths '.' and '..'.\u001b[39;00m\n\u001b[32m    930\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m    932\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_child_relpath(name)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/BraTS-2023'"
          ]
        }
      ],
      "source": [
        "MODS = ['t1n','t1c','t2w','t2f']; SEG='seg'\n",
        "def find_cases(root: pathlib.Path):\n",
        "    return [p for p in sorted(root.iterdir()) if p.is_dir() and any((p/f'{p.name}-{m}.nii.gz').exists() for m in MODS)]\n",
        "def load_case(p: pathlib.Path):\n",
        "    base=p.name\n",
        "    mods=[]\n",
        "    for m in MODS:\n",
        "        a = nib.load(str(p/f'{base}-{m}.nii.gz')).get_fdata().astype(np.float32)\n",
        "        mask = a!=0;\n",
        "        if mask.any(): a=(a - a[mask].mean())/(a[mask].std()+1e-6)\n",
        "        mods.append(a)\n",
        "    seg = nib.load(str(p/f'{base}-{SEG}.nii.gz')).get_fdata().astype(np.int16)\n",
        "    return np.stack(mods,0), seg\n",
        "cases = find_cases(DATA_ROOT)[:CASE_LIMIT]\n",
        "mods0, seg0 = load_case(cases[0])\n",
        "print('Vol shape:', mods0.shape, seg0.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SIREN MLP\n",
        "SIREN uses sine activations with special initialization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def siren_init_first(key, in_dim, out_dim, omega0=30.0):\n",
        "    # Uniform in [-1/in_dim, 1/in_dim]\n",
        "    limit = 1.0/in_dim\n",
        "    W = jax.random.uniform(key, (in_dim, out_dim), minval=-limit, maxval=limit)\n",
        "    b = jnp.zeros((out_dim,))\n",
        "    return {'W': W, 'b': b}\n",
        "def siren_init(key, in_dim, out_dim, omega=30.0):\n",
        "    # Recommended: U(-sqrt(6/in)/omega, sqrt(6/in)/omega)\n",
        "    limit = math.sqrt(6/in_dim)/omega\n",
        "    W = jax.random.uniform(key, (in_dim, out_dim), minval=-limit, maxval=limit)\n",
        "    b = jnp.zeros((out_dim,))\n",
        "    return {'W': W, 'b': b}\n",
        "def init_siren(key, in_dim, hidden, out_dim, omega0=30.0, omega=30.0):\n",
        "    params=[]\n",
        "    dims=[in_dim]+hidden+[out_dim]\n",
        "    # first layer special\n",
        "    key,k1=jax.random.split(key)\n",
        "    params.append(siren_init_first(k1, dims[0], dims[1], omega0))\n",
        "    # hidden\n",
        "    for i in range(1,len(dims)-2):\n",
        "        key,ki=jax.random.split(key)\n",
        "        params.append(siren_init(ki, dims[i], dims[i+1], omega))\n",
        "    # last linear\n",
        "    key,kl=jax.random.split(key)\n",
        "    W = jax.random.uniform(kl, (dims[-2], dims[-1]), minval=-1e-4, maxval=1e-4)\n",
        "    params.append({'W': W, 'b': jnp.zeros((dims[-1],))})\n",
        "    return key, params\n",
        "def apply_siren(params, x, omega0=30.0, omega=30.0):\n",
        "    h=x\n",
        "    h = jnp.sin(jnp.dot(h, params[0]['W']) + params[0]['b']) * 1.0  # first\n",
        "    for layer in params[1:-1]:\n",
        "        h = jnp.sin(jnp.dot(h, layer['W']) + layer['b'])\n",
        "    return jnp.dot(h, params[-1]['W']) + params[-1]['b']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sampling & Distillation Hooks\n",
        "Distillation expects optional teacher logits per voxel (C,H,W,D). Provide files under `TEACHER_DIR` named `<case>-teacher.npz` with array `logits`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_teacher_logits(case_path: pathlib.Path) -> Optional[np.ndarray]:\n",
        "    name = case_path.name\n",
        "    fp = TEACHER_DIR/f'{name}-teacher.npz'\n",
        "    if fp.exists():\n",
        "        d = np.load(fp)\n",
        "        if 'logits' in d: return d['logits']  # (C,H,W,D)\n",
        "    return None\n",
        "\n",
        "def sample_batch_np(key, cases, batch_size):\n",
        "    # Random case, uniform voxel sampling\n",
        "    key, kc, kx, ky, kz = jax.random.split(key, 5)\n",
        "    ci = int(jax.random.randint(kc, (), 0, len(cases)))\n",
        "    mods, seg = load_case(cases[ci])\n",
        "    H,W,D = seg.shape\n",
        "    xs = np.array(jax.random.randint(kx, (batch_size,), 0, H)); ys = np.array(jax.random.randint(ky, (batch_size,), 0, W)); zs = np.array(jax.random.randint(kz, (batch_size,), 0, D))\n",
        "    intens = mods[:, xs, ys, zs].transpose(1,0)\n",
        "    labels = seg[xs, ys, zs].astype(np.int32)\n",
        "    coords = np.stack([xs, ys, zs], axis=-1); norm = (coords / np.array([H-1,W-1,D-1]))*2-1\n",
        "    # teacher (optional)\n",
        "    tlog = load_teacher_logits(cases[ci])\n",
        "    teacher = None\n",
        "    if tlog is not None and tlog.shape[0]==NUM_CLASSES:\n",
        "        teacher = tlog[:, xs, ys, zs].transpose(1,0).astype(np.float32)  # (B,C)\n",
        "    return jnp.array(norm), jnp.array(intens), jnp.array(labels), (teacher, ci)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n",
        "Loss = CE(labels) + KD_WEIGHT * KL(student||teacher) when teacher is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "schedule = optax.warmup_cosine_decay_schedule(0.0, LR, WARMUP, max(1,STEPS-WARMUP), MIN_LR)\n",
        "opt = optax.chain(optax.clip_by_global_norm(1.0), optax.adamw(schedule))\n",
        "\n",
        "# Infer in-dim\n",
        "in_dim = 3 + mods0.shape[0]  # no Fourier here; SIREN learns high-freq via sine\n",
        "key, params = init_siren(key, in_dim, SIREN_HIDDEN, NUM_CLASSES, omega0=OMEGA_0, omega=OMEGA)\n",
        "opt_state = opt.init(params)\n",
        "\n",
        "def forward(params, coords, intens):\n",
        "    x = jnp.concatenate([coords, intens], axis=-1)\n",
        "    return apply_siren(params, x, omega0=OMEGA_0, omega=OMEGA)\n",
        "\n",
        "def loss_batch(params, coords, intens, labels, tsoft=None):\n",
        "    logits = forward(params, coords, intens)\n",
        "    y = jax.nn.one_hot(labels, NUM_CLASSES)\n",
        "    ce = optax.softmax_cross_entropy(logits, y).mean()\n",
        "    if tsoft is not None and KD_WEIGHT>0:\n",
        "        # teacher logits -> soft probs\n",
        "        tp = jax.nn.softmax(jnp.array(tsoft), axis=-1)\n",
        "        sp = jax.nn.log_softmax(logits, axis=-1)\n",
        "        kd = -(tp * sp).sum(-1).mean()  # cross-entropy with teacher probs\n",
        "        return (1-KD_WEIGHT)*ce + KD_WEIGHT*kd\n",
        "    return ce\n",
        "\n",
        "grad_fn = jax.jit(jax.value_and_grad(loss_batch))\n",
        "\n",
        "loss_hist=[]\n",
        "for step in range(1, STEPS+1):\n",
        "    grads_acc = [ {'W': jnp.zeros_like(p['W']), 'b': jnp.zeros_like(p['b'])} for p in params ]\n",
        "    loss_acc = 0.0\n",
        "    for _ in range(ACCUM):\n",
        "        key, sub = jax.random.split(key)\n",
        "        c,i,l, (tsoft,_) = sample_batch_np(sub, cases, MICRO_BATCH)\n",
        "        val, grads = grad_fn(params, c, i, l, tsoft)\n",
        "        loss_acc += float(val)\n",
        "        grads_acc = [ {'W': ga['W']+g['W'], 'b': ga['b']+g['b']} for ga,g in zip(grads_acc, grads) ]\n",
        "    grads_mean = [ {'W': g['W']/ACCUM, 'b': g['b']/ACCUM} for g in grads_acc ]\n",
        "    updates, opt_state = opt.update(grads_mean, opt_state, params)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    loss_hist.append(loss_acc/ACCUM)\n",
        "    if step % 25 == 0 or step==1:\n",
        "        print(f'step {step}/{STEPS} loss={loss_hist[-1]:.4f}')\n",
        "\n",
        "# Save\n",
        "flat={};\n",
        "for k,(layer) in enumerate(params): flat[f'W_{k}']=np.array(layer['W']); flat[f'b_{k}']=np.array(layer['b'])\n",
        "np.savez_compressed(SAVE_PATH, **flat)\n",
        "print('Saved', SAVE_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n",
        "Reconstruct and compute Dice on one case (no teacher needed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_volume(params, mods, seg, chunk=120000):\n",
        "    M,H,W,D = mods.shape\n",
        "    xs,ys,zs = np.arange(H),np.arange(W),np.arange(D)\n",
        "    grid = np.stack(np.meshgrid(xs,ys,zs, indexing='ij'),axis=-1).reshape(-1,3)\n",
        "    intens = mods.transpose(1,2,3,0).reshape(-1,M)\n",
        "    norm = (grid/np.array([H-1,W-1,D-1]))*2-1\n",
        "    outs=[]\n",
        "    for i in range(0,len(grid),chunk):\n",
        "        logits = forward(params, jnp.array(norm[i:i+chunk]), jnp.array(intens[i:i+chunk]))\n",
        "        outs.append(np.array(jnp.argmax(logits,axis=-1), dtype=np.int16))\n",
        "    pred = np.concatenate(outs,0).reshape(H,W,D)\n",
        "    return pred, seg\n",
        "def dice_score(pred,true,C=NUM_CLASSES):\n",
        "    s={}\n",
        "    for c in range(C):\n",
        "        p=(pred==c); t=(true==c); inter=(p&t).sum(); denom=p.sum()+t.sum();\n",
        "        s[c]= (2*inter+1e-6)/(denom+1e-6) if denom>0 else np.nan\n",
        "    return s\n",
        "pred,true = predict_volume(params, mods0, seg0)\n",
        "print('Dice:', dice_score(pred,true))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cis6020",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
