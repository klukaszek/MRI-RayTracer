{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2afaf54-f8f4-48c2-a07c-9237e4e27349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.0\n",
      "NumPy ok (<2): 2.3.4\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, random, os, sys, matplotlib\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"NumPy ok (<2):\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4734dc61-bbf5-4803-9a88-d84addfb2a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1251 rows -> /Users/kylelukaszek/Classes/AI/Project/data/BraTS-2023/manifest.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, re, csv\n",
    "\n",
    "root = Path(\"../data/BraTS-2023\").resolve()\n",
    "cases = sorted([p for p in root.iterdir() if p.is_dir() or p.suffix==\".nii.gz\" or p.suffix==\".gz\"])\n",
    "rows = []\n",
    "\n",
    "def list_files(case_dir):\n",
    "    if case_dir.is_dir():\n",
    "        return [str(p) for p in case_dir.glob(\"*.nii*\")]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "for case in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
    "    files = list_files(case)\n",
    "    pat = {\n",
    "        \"t1\":    r\"-t1n\\.nii\\.gz$|-t1\\.nii\\.gz$\",\n",
    "        \"t1ce\":  r\"-t1c\\.nii\\.gz$|-t1ce\\.nii\\.gz$\",\n",
    "        \"t2\":    r\"-t2w\\.nii\\.gz$|-t2\\.nii\\.gz$\",\n",
    "        \"flair\": r\"-t2f\\.nii\\.gz$|-flair\\.nii\\.gz$\",\n",
    "        \"mask\":  r\"-seg\\.nii\\.gz$\"\n",
    "    }\n",
    "    def pick(rx_pat):\n",
    "        rx = re.compile(rx_pat)\n",
    "        for f in files:\n",
    "            if rx.search(os.path.basename(f)): return f\n",
    "        return \"\"\n",
    "    rows.append({\n",
    "        \"id\": case.name,\n",
    "        \"t1\":    pick(pat[\"t1\"]),\n",
    "        \"t1ce\":  pick(pat[\"t1ce\"]),\n",
    "        \"t2\":    pick(pat[\"t2\"]),\n",
    "        \"flair\": pick(pat[\"flair\"]),\n",
    "        \"mask\":  pick(pat[\"mask\"]),\n",
    "    })\n",
    "\n",
    "out = root / \"manifest.csv\"\n",
    "with open(out, \"w\", newline=\"\") as fp:\n",
    "    w = csv.DictWriter(fp, fieldnames=[\"id\",\"t1\",\"t1ce\",\"t2\",\"flair\",\"mask\"])\n",
    "    w.writeheader(); w.writerows(rows)\n",
    "\n",
    "print(f\"Wrote {len(rows)} rows -> {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3aa261f-1389-4265-9051-83a3e9a571a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Rows: 1251\n"
     ]
    }
   ],
   "source": [
    "import os, random, math, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/BraTS-2023/manifest.csv\")\n",
    "cols = [\"t1\",\"t1ce\",\"t2\",\"flair\",\"mask\"]\n",
    "exists = lambda p: isinstance(p,str) and len(p)>0 and os.path.exists(p)\n",
    "df = df[df[cols].map(exists).all(axis=1)].reset_index(drop=True)\n",
    "print(\"Rows:\", len(df))\n",
    "\n",
    "\n",
    "def load_nii(path):\n",
    "    img = nib.load(path)\n",
    "    data = img.get_fdata().astype(np.float32)\n",
    "    return data, img.header.get_zooms()\n",
    "\n",
    "def norm_img(x):\n",
    "    x = np.nan_to_num(x)\n",
    "    p1, p99 = np.percentile(x, 1), np.percentile(x, 99)\n",
    "    x = np.clip(x, p1, p99)\n",
    "    m, s = x.mean(), x.std()+1e-6\n",
    "    return (x - m) / s\n",
    "\n",
    "\n",
    "def resize_img(x, size=192, mode=\"bilinear\", is_mask=False):\n",
    "    if x.ndim == 3:  # (H,W,C) یا (C,H,W)\n",
    "        if x.shape[0] in (3,4) and x.shape[0] < x.shape[2]:\n",
    "            t = torch.from_numpy(x)[None]\n",
    "        else:\n",
    "            t = torch.from_numpy(x).permute(2,0,1)[None]  # (1,C,H,W)\n",
    "    elif x.ndim == 2:\n",
    "        t = torch.from_numpy(x)[None,None]               # (1,1,H,W)\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected shape:\", x.shape)\n",
    "\n",
    "    if is_mask:\n",
    "        t = F.interpolate(t.float(), size=(size,size), mode=\"nearest\")\n",
    "        t = t[0,0].to(torch.int64)\n",
    "        return t.numpy()\n",
    "    else:\n",
    "        t = F.interpolate(t.float(), size=(size,size), mode=\"bilinear\", align_corners=False)\n",
    "        t = t[0]\n",
    "        if t.shape[0] > 1:\n",
    "            return t.numpy().transpose(1,2,0)\n",
    "        else:\n",
    "            return t[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d4805b-e4df-45a6-8f29-31c84d48e47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 13211  Val samples: 900\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 192\n",
    "MAX_SLICES_PER_CASE_TRAIN = 12\n",
    "MAX_SLICES_PER_CASE_VAL   = 6\n",
    "BATCH_SIZE = 2\n",
    "VAL_SPLIT = 0.12  # ~ 12%\n",
    "\n",
    "all_ids = df[\"id\"].tolist()\n",
    "random.seed(42); random.shuffle(all_ids)\n",
    "val_n = max(1, int(len(all_ids)*VAL_SPLIT))\n",
    "val_ids = set(all_ids[:val_n])\n",
    "train_ids = set(all_ids[val_n:])\n",
    "\n",
    "class BraTSSliceDataset(Dataset):\n",
    "    def __init__(self, df, id_set, max_slices_per_case, include_empty, img_size=IMG_SIZE):\n",
    "        self.records = []\n",
    "        self.img_size = img_size\n",
    "        for _, row in df.iterrows():\n",
    "            cid = row[\"id\"]\n",
    "            if cid not in id_set: \n",
    "                continue\n",
    "            vols = {}\n",
    "            for k in [\"t1\",\"t1ce\",\"t2\",\"flair\",\"mask\"]:\n",
    "                v, _ = load_nii(row[k])\n",
    "                vols[k] = v.astype(np.float32)\n",
    "            \n",
    "            x = np.stack([norm_img(vols[\"t1\"]), norm_img(vols[\"t1ce\"]), norm_img(vols[\"t2\"]), norm_img(vols[\"flair\"])], axis=0)  # (4,H,W,Z)\n",
    "            y = vols[\"mask\"].astype(np.int64)  # (H,W,Z)\n",
    "\n",
    "            H,W,Z = y.shape\n",
    "            zs = list(range(Z))\n",
    "            random.shuffle(zs)\n",
    "            kept = 0\n",
    "            for z in zs:\n",
    "                mask_slice = y[:,:,z]\n",
    "                if not include_empty and mask_slice.max()==0:\n",
    "                    continue\n",
    "                img_slice  = x[:,:,:,z]  # (4,H,W)\n",
    "                # Resize\n",
    "                img_slice_r = resize_img(img_slice.transpose(1,2,0), size=self.img_size, is_mask=False)  # -> (H,W,4)\n",
    "                mask_slice_r= resize_img(mask_slice, size=self.img_size, is_mask=True)                    # -> (H,W)\n",
    "                # CHW\n",
    "                img_chw = np.ascontiguousarray(img_slice_r.transpose(2,0,1))  # (4,H,W)\n",
    "                self.records.append((cid, z, img_chw, mask_slice_r))\n",
    "                kept += 1\n",
    "                if kept >= max_slices_per_case:\n",
    "                    break\n",
    "\n",
    "    def __len__(self): return len(self.records)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        cid,z,x,y = self.records[i]\n",
    "        return {\n",
    "            \"id\": cid, \"z\": z,\n",
    "            \"image\": torch.from_numpy(x).float(),\n",
    "            \"mask\":  torch.from_numpy(y).long()\n",
    "        }\n",
    "\n",
    "train_ds = BraTSSliceDataset(df, train_ids, MAX_SLICES_PER_CASE_TRAIN, include_empty=False)\n",
    "val_ds   = BraTSSliceDataset(df, val_ids,   MAX_SLICES_PER_CASE_VAL,   include_empty=True)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "print(\"Train samples:\", len(train_ds), \" Val samples:\", len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7da29a11-66dc-4909-9eee-45657ce2d719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.928804"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out, 3, padding=1), nn.BatchNorm2d(c_out), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(c_out, c_out, 3, padding=1), nn.BatchNorm2d(c_out), nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class UNet2D(nn.Module):\n",
    "    def __init__(self, in_ch=4, n_classes=4, base=32):\n",
    "        super().__init__()\n",
    "        self.d1 = DoubleConv(in_ch, base)\n",
    "        self.p1 = nn.MaxPool2d(2)\n",
    "        self.d2 = DoubleConv(base, base*2); self.p2 = nn.MaxPool2d(2)\n",
    "        self.d3 = DoubleConv(base*2, base*4); self.p3 = nn.MaxPool2d(2)\n",
    "        self.b  = DoubleConv(base*4, base*8)\n",
    "        self.u3 = nn.ConvTranspose2d(base*8, base*4, 2, stride=2)\n",
    "        self.c3 = DoubleConv(base*8, base*4)\n",
    "        self.u2 = nn.ConvTranspose2d(base*4, base*2, 2, stride=2)\n",
    "        self.c2 = DoubleConv(base*4, base*2)\n",
    "        self.u1 = nn.ConvTranspose2d(base*2, base, 2, stride=2)\n",
    "        self.c1 = DoubleConv(base*2, base)\n",
    "        self.out= nn.Conv2d(base, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.d1(x)\n",
    "        x2 = self.d2(self.p1(x1))\n",
    "        x3 = self.d3(self.p2(x2))\n",
    "        xb = self.b(self.p3(x3))\n",
    "        x  = self.u3(xb); x = self.c3(torch.cat([x,x3], dim=1))\n",
    "        x  = self.u2(x);  x = self.c2(torch.cat([x,x2], dim=1))\n",
    "        x  = self.u1(x);  x = self.c1(torch.cat([x,x1], dim=1))\n",
    "        return self.out(x)\n",
    "\n",
    "model = UNet2D(in_ch=4, n_classes=4).to(device)\n",
    "sum(p.numel() for p in model.parameters())/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f41d75-5a79-4230-8bad-d1b08e9e1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0, n_classes=4):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "        self.n_classes = n_classes\n",
    "    def forward(self, logits, target):\n",
    "        # logits: (B,C,H,W), target: (B,H,W)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        target_1h = torch.nn.functional.one_hot(target, num_classes=self.n_classes).permute(0,3,1,2).float()\n",
    "        dims = (0,2,3)\n",
    "        intersection = (probs * target_1h).sum(dims)\n",
    "        denom = probs.sum(dims) + target_1h.sum(dims)\n",
    "        dice = (2*intersection + self.smooth) / (denom + self.smooth)\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "dice_loss = DiceLoss(n_classes=4)\n",
    "ce_loss   = nn.CrossEntropyLoss()\n",
    "def combo_loss(logits, target, w_dice=0.7, w_ce=0.3):\n",
    "    return w_dice * dice_loss(logits, target) + w_ce * ce_loss(logits, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea624948-a161-4e8b-be64-fe9f0015bfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] train loss=0.3039 dice=0.4895 | val loss=0.2113 dice=0.6568\n",
      "✓ Saved: ./checkpoints/unet2d_braTS.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02] train loss=0.2663 dice=0.5373 | val loss=0.1912 dice=0.6938\n",
      "✓ Saved: ./checkpoints/unet2d_braTS.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03] train loss=0.2131 dice=0.6324 | val loss=0.1797 dice=0.7154\n",
      "✓ Saved: ./checkpoints/unet2d_braTS.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss=0.1884 dice=0.6745:  90%|████████▉ | 5940/6606 [02:45<00:18, 35.56it/s]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "lr = 1e-3\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "def run_epoch(dl, train=True):\n",
    "    model.train(train)\n",
    "    total_loss, total_dice, n = 0.0, 0.0, 0\n",
    "    pbar = tqdm(dl, leave=False)\n",
    "    for batch in pbar:\n",
    "        x = batch[\"image\"].to(device)          # (B,4,H,W)\n",
    "        y = batch[\"mask\"].to(device)           # (B,H,W)\n",
    "        if train:\n",
    "            opt.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = combo_loss(logits, y)\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            pred  = probs.argmax(1)\n",
    "            \n",
    "            dices = []\n",
    "            for cls in [1,2,3]:\n",
    "                inter = ((pred==cls) & (y==cls)).sum().item()\n",
    "                denom = (pred==cls).sum().item() + (y==cls).sum().item()\n",
    "                d = (2*inter)/(denom+1e-6) if denom>0 else 1.0\n",
    "                dices.append(d)\n",
    "            mean_dice = float(np.mean(dices)) if len(dices)>0 else 0.0\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total_loss += float(loss.item()) * x.size(0)\n",
    "        total_dice += mean_dice * x.size(0)\n",
    "        n += x.size(0)\n",
    "        pbar.set_description(f\"{'Train' if train else 'Val'} loss={total_loss/n:.4f} dice={total_dice/n:.4f}\")\n",
    "    return total_loss/n, total_dice/n\n",
    "\n",
    "best = {\"val_dice\": -1, \"path\": \"./checkpoints/unet2d_braTS.pt\"}\n",
    "os.makedirs(\"./checkpoints\", exist_ok=True)\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_dice = run_epoch(train_dl, train=True)\n",
    "    va_loss, va_dice = run_epoch(val_dl,   train=False)\n",
    "    print(f\"[{ep:02d}] train loss={tr_loss:.4f} dice={tr_dice:.4f} | val loss={va_loss:.4f} dice={va_dice:.4f}\")\n",
    "    if va_dice > best[\"val_dice\"]:\n",
    "        best[\"val_dice\"] = va_dice\n",
    "        torch.save({\"model\":model.state_dict()}, best[\"path\"])\n",
    "        print(\"✓ Saved:\", best[\"path\"])\n",
    "print(\"Best val dice:\", best[\"val_dice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128fccbd-85d1-4aae-910c-a1461dfcc91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "samples = 3\n",
    "fig, axes = plt.subplots(samples, 4, figsize=(10, 3*samples))\n",
    "with torch.no_grad():\n",
    "    idxs = np.random.choice(len(val_ds), size=samples, replace=False)\n",
    "    for r,i in enumerate(idxs):\n",
    "        item = val_ds[i]\n",
    "        x = item[\"image\"][None].to(device)\n",
    "        y = item[\"mask\"].cpu().numpy()\n",
    "        logits = model(x); pred = torch.softmax(logits,1).argmax(1)[0].cpu().numpy()\n",
    "\n",
    "        \n",
    "        flair = item[\"image\"][1].cpu().numpy() \n",
    "        flair = item[\"image\"][3].cpu().numpy()  \n",
    "\n",
    "        axes[r,0].imshow(flair, cmap=\"gray\"); axes[r,0].set_title(\"FLAIR\"); axes[r,0].axis(\"off\")\n",
    "        axes[r,1].imshow(y, cmap=\"nipy_spectral\"); axes[r,1].set_title(\"GT mask\"); axes[r,1].axis(\"off\")\n",
    "        axes[r,2].imshow(pred, cmap=\"nipy_spectral\"); axes[r,2].set_title(\"Pred mask\"); axes[r,2].axis(\"off\")\n",
    "        diff = (pred!=y).astype(np.uint8)\n",
    "        axes[r,3].imshow(diff, cmap=\"hot\"); axes[r,3].set_title(\"Error map\"); axes[r,3].axis(\"off\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e28a4-3273-4138-9f23-cc2fb31a68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ckpt_path = \"./checkpoints/unet2d_braTS.pt\"\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(state[\"model\"])\n",
    "model.eval()\n",
    "print(\"Loaded:\", ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8b3e7c-4fbc-41c7-8bf8-92c0d2f9052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import re, os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "MU_BASE = Path(\"../data/MU-Glioma-Post\")\n",
    "\n",
    "def _pick_one(files, patterns):\n",
    "    for p in files:\n",
    "        name = p.name.lower()\n",
    "        for pat in patterns:\n",
    "            if re.search(pat, name):\n",
    "                return p\n",
    "    return None\n",
    "\n",
    "def find_case_mu(base=MU_BASE):\n",
    "    cases = []\n",
    " \n",
    "    for tp in sorted(Path(base).rglob(\"Timepoint_*\")):\n",
    "        files = [p for p in tp.glob(\"*.nii*\")]\n",
    "        if not files:\n",
    "            continue\n",
    "\n",
    "     \n",
    "        t1ce = _pick_one(files, [r\"t1c\", r\"t1ce\", r\"post.*t1\", r\"t1.*post\"])\n",
    "        t1   = _pick_one(files, [r\"t1n\", r\"(?<!c)(?<!ce)(^|[_-])t1([_-]|$)\"])\n",
    "        t2   = _pick_one(files, [r\"t2w\", r\"(^|[_-])t2([_-]|$)\"])\n",
    "        flair= _pick_one(files, [r\"t2f\", r\"flair\"])\n",
    "        mask = _pick_one(files, [r\"mask\", r\"seg\"])\n",
    "\n",
    "        if all([t1, t1ce, t2, flair]):\n",
    "            cases.append({\n",
    "                \"dir\":   str(tp),\n",
    "                \"t1\":    str(t1),\n",
    "                \"t1ce\":  str(t1ce),\n",
    "                \"t2\":    str(t2),\n",
    "                \"flair\": str(flair),\n",
    "                \"mask\":  str(mask) if mask else \"\"\n",
    "            })\n",
    "    return cases\n",
    "\n",
    "mu_cases = find_case_mu()\n",
    "print(\"MU cases found:\", len(mu_cases))\n",
    "for i,c in enumerate(mu_cases[:3]):\n",
    "    print(f\"[{i}] {c['dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb13d8-188c-4904-b6dd-019ce8fa7034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- visualize one MU case with your trained model ----\n",
    "if len(mu_cases):\n",
    "    samp = mu_cases[0]\n",
    "    im_t1,_   = load_nii(samp[\"t1\"])\n",
    "    im_t1ce,_ = load_nii(samp[\"t1ce\"])\n",
    "    im_t2,_   = load_nii(samp[\"t2\"])\n",
    "    im_fl,_   = load_nii(samp[\"flair\"])\n",
    "\n",
    "    img = np.stack([norm_img(im_t1), norm_img(im_t1ce), norm_img(im_t2), norm_img(im_fl)], axis=0)  # (4,H,W,Z)\n",
    "    z = img.shape[-1] // 2\n",
    "    sl = img[:, :, :, z]                                          # (4,H,W)\n",
    "    sl_r = resize_img(sl.transpose(1,2,0), size=IMG_SIZE, is_mask=False)  # -> (H,W,4)\n",
    "    x = torch.from_numpy(sl_r.transpose(2,0,1))[None].float().to(device)  # -> (1,4,H,W)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = torch.softmax(model(x), 1).argmax(1)[0].cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.subplot(1,3,1); plt.imshow(sl_r[:,:,3], cmap=\"gray\"); plt.title(\"FLAIR\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,3,2); plt.imshow(pred, cmap=\"nipy_spectral\"); plt.title(\"Pred\"); plt.axis(\"off\")\n",
    "    if samp[\"mask\"] and os.path.exists(samp[\"mask\"]):\n",
    "        gt,_ = load_nii(samp[\"mask\"])\n",
    "        gt_r = resize_img(gt[:,:,z], size=IMG_SIZE, is_mask=True)\n",
    "        plt.subplot(1,3,3); plt.imshow(gt_r, cmap=\"nipy_spectral\"); plt.title(\"GT\"); plt.axis(\"off\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"No MU cases matched. Check path/patterns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a896c876-a4de-42f5-9108-d16a8ef17c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Phase 2: Distillation dataset creation ==========\n",
    "import torch, numpy as np, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "OUT_PATH = \"./distillation_data\"\n",
    "os.makedirs(OUT_PATH, exist_ok=True)\n",
    "\n",
    "def collect_voxels(df, sample_count=200_000):\n",
    "    vox, labels = [], []\n",
    "    for idx,row in tqdm(df.iterrows(), total=len(df)):\n",
    "        mask,_ = load_nii(row[\"mask\"])\n",
    "        if mask.max()==0: continue\n",
    "        t1,_ = load_nii(row[\"t1\"]); t1ce,_ = load_nii(row[\"t1ce\"])\n",
    "        t2,_ = load_nii(row[\"t2\"]); fl,_ = load_nii(row[\"flair\"])\n",
    "        vol = np.stack([norm_img(t1), norm_img(t1ce), norm_img(t2), norm_img(fl)], axis=0)\n",
    "       \n",
    "        xs, ys, zs = np.random.randint(0,vol.shape[1],sample_count), \\\n",
    "                     np.random.randint(0,vol.shape[2],sample_count), \\\n",
    "                     np.random.randint(0,vol.shape[3],sample_count)\n",
    "        for i in range(sample_count):\n",
    "            vox.append([xs[i]/vol.shape[1], ys[i]/vol.shape[2], zs[i]/vol.shape[3]])\n",
    "            labels.append(int(mask[xs[i],ys[i],zs[i]]))\n",
    "    np.savez_compressed(os.path.join(OUT_PATH,\"samples.npz\"), xyz=np.array(vox), label=np.array(labels))\n",
    "    print(\"Saved:\", len(vox), \"voxels\")\n",
    "\n",
    "collect_voxels(df.sample(20))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458056a4-7f25-48ff-a34a-e46d3760e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Phase 2: Train implicit MLP ==========\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "data = np.load(os.path.join(OUT_PATH,\"samples.npz\"))\n",
    "xyz, label = torch.tensor(data[\"xyz\"],dtype=torch.float32), torch.tensor(data[\"label\"],dtype=torch.long)\n",
    "\n",
    "class VoxelSet(Dataset):\n",
    "    def __len__(self): return len(label)\n",
    "    def __getitem__(self,i): return xyz[i], label[i]\n",
    "\n",
    "loader = DataLoader(VoxelSet(), batch_size=1024, shuffle=True)\n",
    "\n",
    "class ImplicitMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3,64), nn.ReLU(),\n",
    "            nn.Linear(64,64), nn.ReLU(),\n",
    "            nn.Linear(64,4)   \n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "mlp = ImplicitMLP().to(device)\n",
    "opt = torch.optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    total = 0\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = mlp(x)\n",
    "        loss = loss_fn(out,y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total += loss.item()\n",
    "    print(f\"Epoch {epoch+1:02d} | Loss {total/len(loader):.4f}\")\n",
    "\n",
    "torch.save(mlp.state_dict(),\"./checkpoints/implicit_mlp.pth\")\n",
    "print(\"Saved implicit model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432d7281-6bb3-423e-84f7-d27fa27ebdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis6020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
