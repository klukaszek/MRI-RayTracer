{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d8e7f32e",
      "metadata": {},
      "source": [
        "# Fourier Feature INR (Implicit Neural Representation) for BraTS 2023 Tumour Segmentation (JAX)\n",
        "\n",
        "This notebook implements a coordinate-based MLP (implicit neural representation) with Fourier feature embeddings trained to predict voxel-wise tumour labels for BraTS 2023 volumes.\n",
        "\n",
        "Instead of a 3D CNN (e.g. nnU-Net), we treat segmentation as learning a function: \n",
        "$( f: (x,y,z, m_{t1n}, m_{t1c}, m_{t2w}, m_{t2f}) \to \t\\ext{class logits} $).\n",
        "\n",
        "We sample coordinates and associated multi-modal intensities to train an MLP with Fourier features for higher frequency representation capacity.\n",
        "\n",
        "Notes: \n",
        "- This is a proof-of-concept; full convergence requires many iterations.\n",
        "- Memory/time constraints mean we sample sparse coordinates per step.\n",
        "- BraTS labels: 0=background, 1=NCR/NET, 2=ED, 3=ET.\n",
        "- Dice scores are computed per class on a validation case.\n",
        "- Compare conceptually to nnU-Net (dense 3D convolutions + data augmentation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3572bac2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JAX devices: [CpuDevice(id=0)]\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os, math, json, time, pathlib, functools\n",
        "from typing import Tuple, Dict, Any\n",
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "import nibabel as nib\n",
        "from dataclasses import dataclass\n",
        "\n",
        "print('JAX devices:', jax.devices())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8291567",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cases=256 global_batch=32768 micro_batch=2048 accum=16\n"
          ]
        }
      ],
      "source": [
        "# Configuration (Enhanced)\n",
        "DATA_ROOT = pathlib.Path('../data/BraTS-2023')  # training subset root\n",
        "SAVE_PATH = pathlib.Path('../artifacts/inr_brats23.npz')\n",
        "CASE_LIMIT = 128  # training cases used\n",
        "GLOBAL_BATCH_SIZE = 32768\n",
        "MICRO_BATCH_SIZE = 2048\n",
        "FOURIER_FREQS = 16\n",
        "HIDDEN_DIMS = [256, 256, 256, 256]\n",
        "LR = 2e-3\n",
        "MIN_LR = 2e-4\n",
        "WARMUP_STEPS = 50\n",
        "TRAIN_STEPS = 1500\n",
        "VAL_CASE_INDEX = 0\n",
        "RNG_SEED = 42\n",
        "NUM_CLASSES = 4\n",
        "DICE_WEIGHT = 0.2\n",
        "CLASS_WEIGHTS = [0.2,1.0,1.0,1.0]\n",
        "CLIP_NORM = 1.0\n",
        "ACCUM_STEPS = (GLOBAL_BATCH_SIZE + MICRO_BATCH_SIZE - 1)//MICRO_BATCH_SIZE\n",
        "jax_key = jax.random.PRNGKey(RNG_SEED)\n",
        "print(f'Cases={CASE_LIMIT} global_batch={GLOBAL_BATCH_SIZE} micro_batch={MICRO_BATCH_SIZE} accum={ACCUM_STEPS}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8baac498",
      "metadata": {},
      "source": [
        "## Data Loading Utilities\n",
        "We load each BraTS case's modalities and segmentation. Modalities are z-score normalized per volume."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59360bfb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded cases: 256\n",
            "Shape modalities (4, 240, 240, 155) seg shape (240, 240, 155)\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "MODALITY_SUFFIXES = ['t1n', 't1c', 't2w', 't2f']\n",
        "SEG_SUFFIX = 'seg'\n",
        "\n",
        "def find_cases(root: pathlib.Path):\n",
        "    cases = []\n",
        "    for p in sorted(root.iterdir()):\n",
        "        if p.is_dir():\n",
        "            # Expect at least one modality and seg present\n",
        "            if any((p / f'{p.name}-{m}.nii.gz').exists() for m in MODALITY_SUFFIXES):\n",
        "                cases.append(p)\n",
        "    return cases\n",
        "\n",
        "def load_case(case_dir: pathlib.Path) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    base = case_dir.name\n",
        "    mods = []\n",
        "    for suf in MODALITY_SUFFIXES:\n",
        "        fp = case_dir / f'{base}-{suf}.nii.gz'\n",
        "        img = nib.load(str(fp))\n",
        "        arr = img.get_fdata().astype(np.float32)\n",
        "        # z-score normalization ignoring zeros\n",
        "        mask = arr != 0\n",
        "        if mask.any():\n",
        "            mu = arr[mask].mean(); sigma = arr[mask].std() + 1e-6\n",
        "            arr = (arr - mu) / sigma\n",
        "        mods.append(arr)\n",
        "    seg_fp = case_dir / f'{base}-{SEG_SUFFIX}.nii.gz'\n",
        "    seg = nib.load(str(seg_fp)).get_fdata().astype(np.int16)\n",
        "    mods_arr = np.stack(mods, axis=0)  # (M, H, W, D)\n",
        "    return mods_arr, seg\n",
        "\n",
        "all_cases = find_cases(DATA_ROOT)[:CASE_LIMIT]\n",
        "print('Loaded cases:', len(all_cases))\n",
        "sample_mods, sample_seg = load_case(all_cases[0])\n",
        "print('Shape modalities', sample_mods.shape, 'seg shape', sample_seg.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00e574e5",
      "metadata": {},
      "source": [
        "## Coordinate + Feature Sampling\n",
        "We sample random voxel coordinates and gather their modality intensities and labels for stochastic training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e151400",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Volume shape: (240, 240, 155)\n"
          ]
        }
      ],
      "source": [
        "def prepare_case_cache(case_paths):\n",
        "    cache = []\n",
        "    for cp in case_paths:\n",
        "        mods, seg = load_case(cp)\n",
        "        cache.append({'mods': mods, 'seg': seg})\n",
        "    return cache\n",
        "\n",
        "case_cache = prepare_case_cache(all_cases)\n",
        "vol_shape = case_cache[0]['mods'].shape[1:]  # (H,W,D)\n",
        "print('Volume shape:', vol_shape)\n",
        "\n",
        "# Stack cases into device arrays for JAX-friendly sampling\n",
        "mods_np = np.stack([c['mods'] for c in case_cache], axis=0)  # (C,M,H,W,D)\n",
        "segs_np = np.stack([c['seg'] for c in case_cache], axis=0)   # (C,H,W,D)\n",
        "train_mods = jnp.array(mods_np)\n",
        "train_segs = jnp.array(segs_np)\n",
        "C, M, H, W, D = train_mods.shape\n",
        "print('Train arrays:', (C, M, H, W, D))\n",
        "\n",
        "def sample_batch(rng_key, batch_size):\n",
        "    key_case, key_x, key_y, key_z = jax.random.split(rng_key, 4)\n",
        "    ci = jax.random.randint(key_case, (batch_size,), 0, C)\n",
        "    xs = jax.random.randint(key_x, (batch_size,), 0, H)\n",
        "    ys = jax.random.randint(key_y, (batch_size,), 0, W)\n",
        "    zs = jax.random.randint(key_z, (batch_size,), 0, D)\n",
        "    def gather(ci_i, x, y, z):\n",
        "        intens = train_mods[ci_i, :, x, y, z]\n",
        "        lab = train_segs[ci_i, x, y, z]\n",
        "        return intens, lab\n",
        "    intens, labels = jax.vmap(gather)(ci, xs, ys, zs)\n",
        "    coords = jnp.stack([xs, ys, zs], axis=-1)\n",
        "    norm_coords = (coords / (jnp.array([H-1, W-1, D-1]))) * 2.0 - 1.0\n",
        "    return norm_coords, intens, labels.astype(jnp.int32)\n",
        "\n",
        "# Test sampling\n",
        "test_coords, test_feats, test_labels = sample_batch(jax_key, 4)\n",
        "print('Sample coords', test_coords.shape, 'feats', test_feats.shape, 'labels', test_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "761044d9",
      "metadata": {},
      "source": [
        "## Fourier Feature Mapping\n",
        "We map 3D coordinates (normalized) to a higher-dimensional space using sinusoidal functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf624396",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fourier_features(coords: jnp.ndarray, k: int) -> jnp.ndarray:\n",
        "    # coords: (B,3) in [-1,1]\n",
        "    B, dim = coords.shape\n",
        "    freqs = jnp.arange(1, k+1)  # (k,)\n",
        "    # shape (B, dim, k)\n",
        "    ang = coords[..., None] * freqs[None, None, :] * math.pi\n",
        "    sin = jnp.sin(ang); cos = jnp.cos(ang)\n",
        "    ff = jnp.concatenate([sin, cos], axis=-1).reshape(B, dim * 2 * k)\n",
        "    return ff\n",
        "\n",
        "def build_input(coords, intensities):\n",
        "    ff = fourier_features(coords, FOURIER_FREQS)\n",
        "    return jnp.concatenate([coords, ff, intensities], axis=-1)\n",
        "\n",
        "in_dim_test = build_input(test_coords, test_feats).shape[-1]\n",
        "print('Input dim:', in_dim_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c36e3b3a",
      "metadata": {},
      "source": [
        "## MLP Definition (Pure Functions)\n",
        "We define simple MLP parameter initialization and forward apply."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4c9181b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def glorot(key, shape):\n",
        "    fan_in, fan_out = shape[0], shape[1]\n",
        "    limit = math.sqrt(6.0 / (fan_in + fan_out))\n",
        "    return jax.random.uniform(key, shape, minval=-limit, maxval=limit)\n",
        "\n",
        "def init_mlp(key, in_dim, hidden_dims, out_dim):\n",
        "    params = []\n",
        "    dims = [in_dim] + hidden_dims + [out_dim]\n",
        "    for i in range(len(dims)-1):\n",
        "        key, k1, k2 = jax.random.split(key, 3)\n",
        "        W = glorot(k1, (dims[i], dims[i+1]))\n",
        "        b = jnp.zeros((dims[i+1],))\n",
        "        params.append({'W': W, 'b': b})\n",
        "    return key, params\n",
        "\n",
        "def apply_mlp(params, x):\n",
        "    *hidden, last = params\n",
        "    h = x\n",
        "    for layer in hidden:\n",
        "        h = jnp.dot(h, layer['W']) + layer['b']\n",
        "        h = jax.nn.relu(h)\n",
        "    out = jnp.dot(h, last['W']) + last['b']\n",
        "    return out  # logits\n",
        "\n",
        "# Initialize model\n",
        "jax_key, params = init_mlp(jax_key, in_dim_test, HIDDEN_DIMS, NUM_CLASSES)\n",
        "sum_params = sum(p['W'].size + p['b'].size for p in params)\n",
        "print('Total parameters:', sum_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6afced0",
      "metadata": {},
      "source": [
        "## Loss, Optimizer, and Training Step\n",
        "We use cross-entropy loss with Optax Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96bdc02",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimizer, loss, microbatch step\n",
        "schedule = optax.warmup_cosine_decay_schedule(init_value=0.0, peak_value=LR, warmup_steps=WARMUP_STEPS, decay_steps=max(1, TRAIN_STEPS-WARMUP_STEPS), end_value=MIN_LR)\n",
        "optimizer = optax.chain(optax.clip_by_global_norm(CLIP_NORM), optax.adamw(schedule))\n",
        "opt_state = optimizer.init(params)\n",
        "cw = jnp.array(CLASS_WEIGHTS)\n",
        "def one_hot(labels, num_classes): return jax.nn.one_hot(labels, num_classes)\n",
        "def soft_dice(probs, onehot, eps=1e-6):\n",
        "    inter = jnp.sum(probs * onehot, axis=0); sums = jnp.sum(probs, axis=0) + jnp.sum(onehot, axis=0)\n",
        "    return ((2*inter + eps)/(sums + eps)).mean()\n",
        "def loss_fn(params, coords, intensities, labels):\n",
        "    x = build_input(coords, intensities)\n",
        "    logits = apply_mlp(params, x)\n",
        "    y = one_hot(labels, NUM_CLASSES)\n",
        "    ce = optax.softmax_cross_entropy(logits, y)\n",
        "    w = jnp.take(cw, labels); ce = (ce * w).mean()\n",
        "    if DICE_WEIGHT>0:\n",
        "        probs = jax.nn.softmax(logits, axis=-1); dice = soft_dice(probs, y)\n",
        "        return (1-DICE_WEIGHT)*ce + DICE_WEIGHT*(1-dice)\n",
        "    return ce\n",
        "loss_and_grad = jax.jit(jax.value_and_grad(loss_fn))\n",
        "def microbatch_step(params, opt_state, rng_key):\n",
        "    grads_acc = [ {'W': jnp.zeros_like(p['W']), 'b': jnp.zeros_like(p['b'])} for p in params ]\n",
        "    loss_acc = 0.0; key = rng_key\n",
        "    for _ in range(ACCUM_STEPS):\n",
        "        key, sub = jax.random.split(key)\n",
        "        coords, feats, labels = sample_batch(sub, MICRO_BATCH_SIZE)\n",
        "        loss_val, grads = loss_and_grad(params, coords, feats, labels)\n",
        "        loss_acc += float(loss_val)\n",
        "        grads_acc = [ {'W': ga['W']+g['W'], 'b': ga['b']+g['b']} for ga,g in zip(grads_acc, grads) ]\n",
        "    grads_mean = [ {'W': g['W']/ACCUM_STEPS, 'b': g['b']/ACCUM_STEPS} for g in grads_acc ]\n",
        "    updates, opt_state = optimizer.update(grads_mean, opt_state, params)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    return params, opt_state, loss_acc/ACCUM_STEPS\n",
        "jax_key, warm_key = jax.random.split(jax_key)\n",
        "params, opt_state, warm_loss = microbatch_step(params, opt_state, warm_key)\n",
        "print('Warm-up loss', warm_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29ff0ac7",
      "metadata": {},
      "source": [
        "## Training Loop\n",
        "We iterate for a small number of steps (increase TRAIN_STEPS for better results)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df72210c",
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_history = []\n",
        "start = time.time()\n",
        "for step in range(1, TRAIN_STEPS+1):\n",
        "    jax_key, step_key = jax.random.split(jax_key)\n",
        "    params, opt_state, loss_val = microbatch_step(params, opt_state, step_key)\n",
        "    loss_history.append(float(loss_val))\n",
        "    if step % 25 == 0 or step == 1:\n",
        "        print(f'Step {step}/{TRAIN_STEPS} loss={loss_val:.4f}')\n",
        "print('Training time: {:.2f}s'.format(time.time()-start))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5efd2c5",
      "metadata": {},
      "source": [
        "## Evaluation (Reconstruct Full Segmentation for One Case)\n",
        "We reconstruct the segmentation by querying the model on all voxel coordinates of the validation case (chosen by VAL_CASE_INDEX). Then compute Dice per class. To avoid memory overflow, we chunk coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89253c7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_volume(params, case_data, chunk=200000):\n",
        "    mods = case_data['mods']  # (M,H,W,D)\n",
        "    seg_true = case_data['seg']\n",
        "    M, H, W, D = mods.shape\n",
        "    # Build coordinate grid\n",
        "    xs, ys, zs = np.arange(H), np.arange(W), np.arange(D)\n",
        "    grid = np.stack(np.meshgrid(xs, ys, zs, indexing='ij'), axis=-1).reshape(-1,3)  # (N,3)\n",
        "    intens = mods.transpose(1,2,3,0).reshape(-1, M)  # align with grid\n",
        "    # Normalize coords\n",
        "    norm_coords = (grid / np.array([H-1, W-1, D-1])) * 2.0 - 1.0\n",
        "    preds = []\n",
        "    for i in range(0, len(grid), chunk):\n",
        "        c_chunk = jnp.array(norm_coords[i:i+chunk])\n",
        "        f_chunk = jnp.array(intens[i:i+chunk])\n",
        "        x_in = build_input(c_chunk, f_chunk)\n",
        "        logits = apply_mlp(params, x_in)\n",
        "        cls = jnp.argmax(logits, axis=-1)\n",
        "        preds.append(np.array(cls, dtype=np.int16))\n",
        "    pred_flat = np.concatenate(preds, axis=0)\n",
        "    pred_vol = pred_flat.reshape(H, W, D)\n",
        "    return pred_vol, seg_true\n",
        "\n",
        "def dice_score(pred, true, num_classes):\n",
        "    scores = {}\n",
        "    for c in range(num_classes):\n",
        "        pred_c = (pred == c)\n",
        "        true_c = (true == c)\n",
        "        inter = (pred_c & true_c).sum()\n",
        "        denom = pred_c.sum() + true_c.sum()\n",
        "        dice = (2*inter + 1e-6) / (denom + 1e-6) if denom > 0 else np.nan\n",
        "        scores[c] = dice\n",
        "    return scores\n",
        "\n",
        "val_case = case_cache[VAL_CASE_INDEX]\n",
        "pred_vol, true_vol = predict_volume(params, val_case, chunk=120000)\n",
        "scores = dice_score(pred_vol, true_vol, NUM_CLASSES)\n",
        "print('Dice scores:', scores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46607348",
      "metadata": {},
      "source": [
        "## Visualization (Middle Slices)\n",
        "We show all modalities with ground-truth and predicted segmentation overlays.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d93ef75b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "mid_z = pred_vol.shape[2]//2\n",
        "import numpy as _np\n",
        "\n",
        "def _dice_macro_slice(pred2d, true2d, num_classes=4):\n",
        "    scores = []\n",
        "    for c in range(num_classes):\n",
        "        p = (pred2d == c)\n",
        "        t = (true2d == c)\n",
        "        inter = (p & t).sum()\n",
        "        denom = p.sum() + t.sum()\n",
        "        if denom > 0:\n",
        "            scores.append((2*inter + 1e-6) / (denom + 1e-6))\n",
        "    return float(_np.mean(scores)) if len(scores)>0 else float('nan')\n",
        "\n",
        "def _psnr_slice(pred2d, true2d, max_val=3.0):\n",
        "    mse = _np.mean((_np.asarray(pred2d, dtype=_np.float32) - _np.asarray(true2d, dtype=_np.float32))**2)\n",
        "    if mse <= 1e-12:\n",
        "        return float('inf')\n",
        "    return float(10.0 * _np.log10((max_val*max_val) / (mse + 1e-12)))\n",
        "\n",
        "def visualize_modalities_with_overlays(mods, seg_gt, seg_pred, z):\n",
        "    M = mods.shape[0]\n",
        "    fig, axes = plt.subplots(2, M, figsize=(3*M, 6))\n",
        "    if M == 1:\n",
        "        axes = _np.array([[axes[0]],[axes[1]]], dtype=object)\n",
        "    for m in range(M):\n",
        "        ax_gt = axes[0, m]\n",
        "        ax_pred = axes[1, m]\n",
        "        # Ground truth overlay\n",
        "        ax_gt.imshow(mods[m,:,:,z], cmap='gray')\n",
        "        ax_gt.imshow(seg_gt[:,:,z], cmap='tab10', alpha=0.35, vmin=0, vmax=3)\n",
        "        ax_gt.set_title(f'Mod {m} + GT', fontsize=10)\n",
        "        ax_gt.axis('off')\n",
        "        # Prediction overlay with metrics annotation box\n",
        "        ax_pred.imshow(mods[m,:,:,z], cmap='gray')\n",
        "        ax_pred.imshow(seg_pred[:,:,z], cmap='tab10', alpha=0.35, vmin=0, vmax=3)\n",
        "        d = _dice_macro_slice(seg_pred[:,:,z], seg_gt[:,:,z], num_classes=4)\n",
        "        p = _psnr_slice(seg_pred[:,:,z], seg_gt[:,:,z], max_val=3.0)\n",
        "        ax_pred.set_title(f'Mod {m} + Pred', fontsize=10)\n",
        "        ax_pred.text(0.01, 0.99, f'Dice {d:.3f} PSNR {p:.2f} dB',\n",
        "                   transform=ax_pred.transAxes, ha='left', va='top', fontsize=8,\n",
        "                   color='yellow', bbox=dict(boxstyle='round', fc='black', alpha=0.5, pad=0.4))\n",
        "        ax_pred.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Show current validation case slice with metrics (non-overlapping)\n",
        "visualize_modalities_with_overlays(val_case['mods'], true_vol, pred_vol, mid_z)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec3f8f6",
      "metadata": {},
      "source": [
        "## Save Parameters\n",
        "We save learned parameters for reuse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0075a221",
      "metadata": {},
      "outputs": [],
      "source": [
        "flat_params = {}\n",
        "for i, layer in enumerate(params):\n",
        "    flat_params[f'W_{i}'] = np.array(layer['W'])\n",
        "    flat_params[f'b_{i}'] = np.array(layer['b'])\n",
        "np.savez_compressed(SAVE_PATH, **flat_params)\n",
        "print('Saved parameters to', SAVE_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6974ec57",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "- Increase TRAIN_STEPS, CASE_LIMIT for better accuracy.\n",
        "- Add class rebalancing or focal loss (BraTS class imbalance).\n",
        "- Integrate data augmentations (intensity shifts, coordinate jitter).\n",
        "- Compare against nnU-Net baseline metrics.\n",
        "- Explore multi-resolution coordinate conditioning or SIREN activations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be8c814a",
      "metadata": {},
      "source": [
        "## Hold-Out Case Evaluation\n",
        "We evaluate the model on a case not included in the training subset (beyond CASE_LIMIT). If unavailable, we skip.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "300ae923",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_cases_full = find_cases(DATA_ROOT)\n",
        "extra_cases = all_cases_full[CASE_LIMIT:]\n",
        "print('Hold-out cases available:', len(extra_cases))\n",
        "if len(extra_cases) > 0:\n",
        "    hold_case_path = extra_cases[1]\n",
        "    hold_mods, hold_seg = load_case(hold_case_path)\n",
        "    hold_case_data = {'mods': hold_mods, 'seg': hold_seg}\n",
        "    hold_pred, hold_true = predict_volume(params, hold_case_data, chunk=120000)\n",
        "    hold_scores = dice_score(hold_pred, hold_true, NUM_CLASSES)\n",
        "    print('Hold-out Dice:', hold_scores)\n",
        "    mid_z_hold = hold_pred.shape[2]//2\n",
        "    visualize_modalities_with_overlays(hold_mods, hold_true, hold_pred, mid_z_hold)\n",
        "else:\n",
        "    print('No hold-out case beyond training CASE_LIMIT to evaluate.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4edcd918",
      "metadata": {},
      "source": [
        "## Interactive Viewer (Hold-outs)\n",
        "Use the dropdown to select a hold-out case and slider to browse slices. The layout (all modalities with GT and Pred overlays) remains fixed; only the slice changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec9079d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import pathlib as _pl\n",
        "\n",
        "# Prepare hold-out cases list\n",
        "all_cases_full = find_cases(DATA_ROOT)\n",
        "extra_cases = all_cases_full[CASE_LIMIT:]\n",
        "case_options = [(p.name, str(p)) for p in extra_cases]\n",
        "print('Hold-out cases:', len(case_options))\n",
        "\n",
        "hold_pred_cache = {}  # path -> pred volume\n",
        "state = {'mods': None, 'true': None, 'pred': None}\n",
        "\n",
        "def load_and_predict_cached(case_path_str):\n",
        "    p = _pl.Path(case_path_str)\n",
        "    mods, seg = load_case(p)\n",
        "    if case_path_str not in hold_pred_cache:\n",
        "        pred, _ = predict_volume(params, {'mods': mods, 'seg': seg}, chunk=120000)\n",
        "        hold_pred_cache[case_path_str] = pred\n",
        "    return mods, seg, hold_pred_cache[case_path_str]\n",
        "\n",
        "out = widgets.Output()\n",
        "if len(case_options) == 0:\n",
        "    print('No hold-out cases available to visualize.')\n",
        "else:\n",
        "    dd_hold = widgets.Dropdown(options=case_options, description='Hold-out:')\n",
        "    # Initialize\n",
        "    state['mods'], state['true'], state['pred'] = load_and_predict_cached(dd_hold.value)\n",
        "    z_slider = widgets.IntSlider(min=0, max=int(state['pred'].shape[2]-1), value=int(state['pred'].shape[2]//2), description='Slice z')\n",
        "\n",
        "    def render_slice(z):\n",
        "        with out:\n",
        "            clear_output(wait=True)\n",
        "            visualize_modalities_with_overlays(state['mods'], state['true'], state['pred'], int(z))\n",
        "\n",
        "    def on_slice_change(change):\n",
        "        render_slice(change['new'])\n",
        "\n",
        "    def on_case_change(change):\n",
        "        state['mods'], state['true'], state['pred'] = load_and_predict_cached(change['new'])\n",
        "        z_slider.max = int(state['pred'].shape[2]-1)\n",
        "        z_slider.value = int(state['pred'].shape[2]//2)\n",
        "        render_slice(z_slider.value)\n",
        "\n",
        "    z_slider.observe(on_slice_change, names='value')\n",
        "    dd_hold.observe(on_case_change, names='value')\n",
        "    display(widgets.VBox([dd_hold, z_slider, out]))\n",
        "    render_slice(z_slider.value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b55b68bc-83a0-4194-9658-579d5cb50eb7",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cis6020",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
